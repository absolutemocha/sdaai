{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37OLw6k0lVXU"
   },
   "source": [
    "# Deep Learning Fundamentals - LU02 Lab Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzhdzUo6lVXV"
   },
   "source": [
    "## 2.1 Import required package and load data from file into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 60806,
     "status": "ok",
     "timestamp": 1601470497166,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "yeKCE3BxlVXW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1359, 80)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import regularizers\n",
    "\n",
    "# Import the data using the file path\n",
    "data = pd.read_csv('Ames_Housing_Sales.csv', sep=',')\n",
    "print('Data shape: {}'.format(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YN7zhv5lVXa"
   },
   "source": [
    "## 2.2 Data Preparation\n",
    "Extract the label column containing the SalePrice and remove from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 60797,
     "status": "ok",
     "timestamp": 1601470497169,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "MCNT3DB3lVXc"
   },
   "outputs": [],
   "source": [
    "y_col_name = 'SalePrice'\n",
    "y_data = data[y_col_name]\n",
    "\n",
    "x_data = data.drop(y_col_name, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9UtFw-1lVXg"
   },
   "source": [
    "Perform One-Hot Encoding on all categorical data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 60790,
     "status": "ok",
     "timestamp": 1601470497169,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "rxxEzqPblVXg",
    "outputId": "9e2e77a8-0f38-45bb-b29e-81c8039a19e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical data shape: (1359, 258)\n"
     ]
    }
   ],
   "source": [
    "# OneHot Encode categorical data\n",
    "categorical_data = x_data.select_dtypes(include=['object']).copy()\n",
    "for col in categorical_data.columns:\n",
    "    categorical_data[col] = categorical_data[col].astype('category')\n",
    "\n",
    "categorical_data = pd.get_dummies(categorical_data)\n",
    "print('Categorical data shape: {}'.format(categorical_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00MdVu_QlVXk"
   },
   "source": [
    "Normalize data scales for numerical data and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 60787,
     "status": "ok",
     "timestamp": 1601470497170,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "WqCSMDpolVXk"
   },
   "outputs": [],
   "source": [
    "# Standard Scale numerial feature data\n",
    "numerical_data = x_data.select_dtypes(include=['float64', 'int64']).copy()\n",
    "data_tmp = numerical_data.values #returns a numpy array\n",
    "std_scaler = StandardScaler()\n",
    "data_tmp = std_scaler.fit_transform(data_tmp)\n",
    "numerical_data = pd.DataFrame(data_tmp, columns=numerical_data.columns)\n",
    "\n",
    "# Standard Scale numerial label data\n",
    "y_tmp = pd.DataFrame(y_data).values #returns a numpy array\n",
    "y_scaler = MinMaxScaler()\n",
    "y_tmp = y_scaler.fit_transform(y_tmp)\n",
    "y_tmp = y_tmp.reshape(-1)\n",
    "y_data = pd.Series(y_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 60781,
     "status": "ok",
     "timestamp": 1601470497171,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "OCpXZH11lVXn",
    "outputId": "8811fac0-fe60-484e-be6f-90edd2369dd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data data shape: (1359, 294)\n"
     ]
    }
   ],
   "source": [
    "# Combine categorial and numerical data\n",
    "x_data = pd.concat([numerical_data, categorical_data], axis=1)\n",
    "print('x_data data shape: {}'.format(x_data.shape))\n",
    "\n",
    "x_col_name = x_data.columns\n",
    "x_col_count = len(x_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train data shape: (951, 294)\n",
      "X_test data shape: (204, 294)\n",
      "X_val data shape: (204, 294)\n",
      "Epoch 1/20\n",
      "119/119 [==============================] - 1s 2ms/step - loss: 0.0263 - mae: 0.1139 - val_loss: 0.0099 - val_mae: 0.0719\n",
      "Epoch 2/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0070 - mae: 0.0592 - val_loss: 0.0064 - val_mae: 0.0572\n",
      "Epoch 3/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0053 - mae: 0.0502 - val_loss: 0.0047 - val_mae: 0.0501\n",
      "Epoch 4/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0042 - mae: 0.0438 - val_loss: 0.0037 - val_mae: 0.0439\n",
      "Epoch 5/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0385 - val_loss: 0.0030 - val_mae: 0.0391\n",
      "Epoch 6/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0030 - mae: 0.0347 - val_loss: 0.0026 - val_mae: 0.0366\n",
      "Epoch 7/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0027 - mae: 0.0318 - val_loss: 0.0022 - val_mae: 0.0326\n",
      "Epoch 8/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0297 - val_loss: 0.0020 - val_mae: 0.0312\n",
      "Epoch 9/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0277 - val_loss: 0.0017 - val_mae: 0.0288\n",
      "Epoch 10/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0257 - val_loss: 0.0017 - val_mae: 0.0278\n",
      "Epoch 11/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0247 - val_loss: 0.0016 - val_mae: 0.0263\n",
      "Epoch 12/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0239 - val_loss: 0.0015 - val_mae: 0.0257\n",
      "Epoch 13/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0236 - val_loss: 0.0015 - val_mae: 0.0245\n",
      "Epoch 14/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0240 - val_loss: 0.0014 - val_mae: 0.0247\n",
      "Epoch 15/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0225 - val_loss: 0.0015 - val_mae: 0.0249\n",
      "Epoch 16/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0227 - val_loss: 0.0016 - val_mae: 0.0255\n",
      "Epoch 17/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0229 - val_loss: 0.0019 - val_mae: 0.0302\n",
      "Epoch 18/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0228 - val_loss: 0.0016 - val_mae: 0.0251\n",
      "Epoch 19/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0230 - val_loss: 0.0017 - val_mae: 0.0272\n",
      "Epoch 20/20\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0222 - val_loss: 0.0017 - val_mae: 0.0273\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(1, activation='sigmoid', input_shape=(x_col_count,)))\n",
    "network.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Split data into train-test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5)\n",
    "\n",
    "print('X_train data shape: {}'.format(X_train.shape))\n",
    "print('X_test data shape: {}'.format(X_test.shape))\n",
    "print('X_val data shape: {}'.format(X_val.shape))\n",
    "\n",
    "# Pass the validation data into the fit method directory\n",
    "history = network.fit(X_train, y_train, epochs=20, batch_size=8, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train data shape: (815, 294)\n",
      "X_test data shape: (544, 294)\n",
      "Epoch 1/20\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0884 - val_loss: 0.0075 - val_mae: 0.0651\n",
      "Epoch 2/20\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0523 - val_loss: 0.0048 - val_mae: 0.0520\n",
      "Epoch 3/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0042 - mae: 0.0442 - val_loss: 0.0038 - val_mae: 0.0459\n",
      "Epoch 4/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0401 - val_loss: 0.0033 - val_mae: 0.0423\n",
      "Epoch 5/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0030 - mae: 0.0370 - val_loss: 0.0026 - val_mae: 0.0384\n",
      "Epoch 6/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0026 - mae: 0.0340 - val_loss: 0.0025 - val_mae: 0.0369\n",
      "Epoch 7/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0327 - val_loss: 0.0027 - val_mae: 0.0378\n",
      "Epoch 8/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0021 - val_mae: 0.0337\n",
      "Epoch 9/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0294 - val_loss: 0.0020 - val_mae: 0.0336\n",
      "Epoch 10/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0292 - val_loss: 0.0021 - val_mae: 0.0334\n",
      "Epoch 11/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 0.0024 - val_mae: 0.0350\n",
      "Epoch 12/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 0.0020 - val_mae: 0.0322\n",
      "Epoch 13/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0022 - val_mae: 0.0348\n",
      "Epoch 14/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0266 - val_loss: 0.0019 - val_mae: 0.0316\n",
      "Epoch 15/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0255 - val_loss: 0.0020 - val_mae: 0.0312\n",
      "Epoch 16/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 0.0019 - val_mae: 0.0315\n",
      "Epoch 17/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0251 - val_loss: 0.0019 - val_mae: 0.0308\n",
      "Epoch 18/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0241 - val_loss: 0.0020 - val_mae: 0.0313\n",
      "Epoch 19/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0239 - val_loss: 0.0020 - val_mae: 0.0311\n",
      "Epoch 20/20\n",
      "82/82 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 0.0019 - val_mae: 0.0310\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(1, activation='sigmoid', input_shape=(x_col_count,)))\n",
    "network.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Split data into train-test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.4)\n",
    "\n",
    "print('X_train data shape: {}'.format(X_train.shape))\n",
    "print('X_test data shape: {}'.format(X_test.shape))\n",
    "\n",
    "# Specify the validation split in the fit method\n",
    "history = network.fit(X_train, y_train, epochs=20, batch_size=8, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8unMIG8ku6d1"
   },
   "source": [
    "## 2.4 Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 728
    },
    "executionInfo": {
     "elapsed": 1791,
     "status": "ok",
     "timestamp": 1601471533684,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "lq7Q4mZelVXu",
    "outputId": "c751440d-e930-42ca-fbd2-fd57d3eb2daa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.0169 - mae: 0.0903 - val_loss: 0.0046 - val_mae: 0.0486\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0060 - mae: 0.0503 - val_loss: 0.0031 - val_mae: 0.0423\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0048 - mae: 0.0443 - val_loss: 0.0024 - val_mae: 0.0377\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0041 - mae: 0.0404 - val_loss: 0.0021 - val_mae: 0.0352\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0367 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0031 - mae: 0.0346 - val_loss: 0.0017 - val_mae: 0.0304\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0028 - mae: 0.0319 - val_loss: 0.0015 - val_mae: 0.0291\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0300 - val_loss: 0.0015 - val_mae: 0.0288\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0282 - val_loss: 0.0014 - val_mae: 0.0267\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0277 - val_loss: 0.0013 - val_mae: 0.0265\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0260 - val_loss: 0.0012 - val_mae: 0.0247\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0252 - val_loss: 0.0012 - val_mae: 0.0235\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0245 - val_loss: 0.0011 - val_mae: 0.0233\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0235 - val_loss: 0.0011 - val_mae: 0.0228\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0233 - val_loss: 0.0011 - val_mae: 0.0231\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0231 - val_loss: 0.0011 - val_mae: 0.0227\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0229 - val_loss: 0.0011 - val_mae: 0.0225\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0227 - val_loss: 0.0013 - val_mae: 0.0250\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0225 - val_loss: 0.0012 - val_mae: 0.0237\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0211 - val_loss: 0.0012 - val_mae: 0.0226\n"
     ]
    }
   ],
   "source": [
    "# Split data into train-test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3)\n",
    "\n",
    "network = models.Sequential()\n",
    "\n",
    "# This is 1 input layer of x_col_count nodes and 1 output later of 1 node\n",
    "network.add(layers.Dense(1, activation='sigmoid', input_shape=(x_col_count,)))\n",
    "\n",
    "# >>>>>>>>> the following set is a sample if to create multiple layer >>>>>>>>>>>>>\n",
    "#example to create multiple layers. the following example is \n",
    "# 1 input layer of x_col_count nodes \n",
    "# 2 hidden layers of 5 and 3 nodes respectively\n",
    "# 1 output layer of 1 node on predicted sales pricing\n",
    "#network.add(layers.Dense(3, activation='relu', input_shape=(x_col_count,)))\n",
    "#network.add(layers.Dense(1, activation='sigmoid'))\n",
    "# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "# Observe the use loss function in the codes below\n",
    "#network.compile(optimizer='sgd',\n",
    "#                loss='mean_squared_error',\n",
    "#               metrics=['mse'])\n",
    "\n",
    "# Observe the setting of shuffle to True\n",
    "# Play around the epochs, batch_size to see the effect \n",
    "# (Try to achieve <0.001 loss)\n",
    "nr.seed(9898)\n",
    "\n",
    "network.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Plot loss and accuracy graph\n",
    "history = network.fit(X_train, y_train, epochs=20, batch_size=8, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qo4vIpgq4mju"
   },
   "source": [
    "## 2.5 Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 2782,
     "status": "ok",
     "timestamp": 1601471534681,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "wT6SpU8Qdd-C",
    "outputId": "7f409ba9-2ec7-4514-c337-5aa37376d757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0275\n",
      "Test loss: 0.0023\n",
      "Test mae: 0.0275\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae = network.evaluate(X_test, y_test)\n",
    "print('Test loss: {:.4f}'.format(test_loss))\n",
    "print('Test mae: {:.4f}'.format(test_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruBXcRTbdmL7"
   },
   "source": [
    "## 2.5.1 Add the codes for plotting the graph to visualise the evaluation. \n",
    "Note: You will need to amend the fit to support the plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 2775,
     "status": "ok",
     "timestamp": 1601471534683,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "u9_eiZxSBQ-H",
    "outputId": "5ccd8043-c4c8-4244-8c1c-8c67064c5c49"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_loss(history):\n",
    "    train_loss = history.history['loss']\n",
    "    test_loss = history.history['val_loss']\n",
    "    x = list(range(1, len(test_loss) + 1))\n",
    "    plt.plot(x, test_loss, color = 'red', label = 'Val MSE')\n",
    "    plt.plot(x, train_loss, label = 'Train MSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('MSE vs. Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "plot_loss(history)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 2771,
     "status": "ok",
     "timestamp": 1601471534683,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "fKbXNsHgC698",
    "outputId": "4e4b415c-727b-45c9-85ff-3c1a5ab71316"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_mse(history):\n",
    "    train_acc = history.history['mae']\n",
    "    test_acc = history.history['val_mae']\n",
    "    x = list(range(1, len(test_acc) + 1))\n",
    "    plt.plot(x, test_acc, color = 'red', label = 'Val MAE')\n",
    "    plt.plot(x, train_acc, label = 'Train MAE')  \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('MAE vs. Epoch')  \n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "plot_mse(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qDWwPsg4pbS"
   },
   "source": [
    "## 2.6 Perform a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 3317,
     "status": "ok",
     "timestamp": 1601471535234,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "wMeCC09I0va4"
   },
   "outputs": [],
   "source": [
    "predictData = pd.read_csv('PredictTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 3315,
     "status": "ok",
     "timestamp": 1601471535235,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "228xIXg6eCIq",
    "outputId": "68b83d28-8fb7-4f0a-87d3-c55eb81aae23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding missing feature Alley_Grvl\n",
      "Adding missing feature BldgType_2fmCon\n",
      "Adding missing feature BldgType_Duplex\n",
      "Adding missing feature BldgType_Twnhs\n",
      "Adding missing feature BsmtCond_Fa\n",
      "Adding missing feature BsmtFinType2_ALQ\n",
      "Adding missing feature BsmtFinType2_BLQ\n",
      "Adding missing feature BsmtFinType2_GLQ\n",
      "Adding missing feature BsmtQual_Fa\n",
      "Adding missing feature Condition1_Feedr\n",
      "Adding missing feature Condition1_PosA\n",
      "Adding missing feature Condition1_PosN\n",
      "Adding missing feature Condition1_RRAe\n",
      "Adding missing feature Condition1_RRAn\n",
      "Adding missing feature Condition1_RRNe\n",
      "Adding missing feature Condition1_RRNn\n",
      "Adding missing feature Condition2_Artery\n",
      "Adding missing feature Condition2_Feedr\n",
      "Adding missing feature Condition2_PosA\n",
      "Adding missing feature Condition2_PosN\n",
      "Adding missing feature Condition2_RRAe\n",
      "Adding missing feature Condition2_RRAn\n",
      "Adding missing feature Condition2_RRNn\n",
      "Adding missing feature Electrical_FuseP\n",
      "Adding missing feature Electrical_Mix\n",
      "Adding missing feature ExterCond_Ex\n",
      "Adding missing feature ExterCond_Fa\n",
      "Adding missing feature ExterQual_Fa\n",
      "Adding missing feature Exterior1st_AsbShng\n",
      "Adding missing feature Exterior1st_BrkComm\n",
      "Adding missing feature Exterior1st_BrkFace\n",
      "Adding missing feature Exterior1st_CBlock\n",
      "Adding missing feature Exterior1st_ImStucc\n",
      "Adding missing feature Exterior1st_Stone\n",
      "Adding missing feature Exterior1st_Stucco\n",
      "Adding missing feature Exterior1st_WdShing\n",
      "Adding missing feature Exterior2nd_AsbShng\n",
      "Adding missing feature Exterior2nd_AsphShn\n",
      "Adding missing feature Exterior2nd_Brk Cmn\n",
      "Adding missing feature Exterior2nd_BrkFace\n",
      "Adding missing feature Exterior2nd_CBlock\n",
      "Adding missing feature Exterior2nd_ImStucc\n",
      "Adding missing feature Exterior2nd_Other\n",
      "Adding missing feature Exterior2nd_Stone\n",
      "Adding missing feature Exterior2nd_Stucco\n",
      "Adding missing feature Exterior2nd_Wd Shng\n",
      "Adding missing feature Fence_MnWw\n",
      "Adding missing feature FireplaceQu_Fa\n",
      "Adding missing feature FireplaceQu_Po\n",
      "Adding missing feature Foundation_Slab\n",
      "Adding missing feature Foundation_Wood\n",
      "Adding missing feature Functional_Maj1\n",
      "Adding missing feature Functional_Maj2\n",
      "Adding missing feature Functional_Mod\n",
      "Adding missing feature Functional_Sev\n",
      "Adding missing feature GarageCond_Ex\n",
      "Adding missing feature GarageCond_Fa\n",
      "Adding missing feature GarageCond_Gd\n",
      "Adding missing feature GarageQual_Ex\n",
      "Adding missing feature GarageQual_Gd\n",
      "Adding missing feature GarageQual_Po\n",
      "Adding missing feature GarageType_2Types\n",
      "Adding missing feature GarageType_BuiltIn\n",
      "Adding missing feature GarageType_CarPort\n",
      "Adding missing feature Heating_Floor\n",
      "Adding missing feature Heating_GasW\n",
      "Adding missing feature Heating_OthW\n",
      "Adding missing feature Heating_Wall\n",
      "Adding missing feature HeatingQC_Po\n",
      "Adding missing feature HouseStyle_1.5Fin\n",
      "Adding missing feature HouseStyle_2.5Unf\n",
      "Adding missing feature LandContour_HLS\n",
      "Adding missing feature LandContour_Low\n",
      "Adding missing feature LandSlope_Sev\n",
      "Adding missing feature LotConfig_Corner\n",
      "Adding missing feature LotConfig_FR3\n",
      "Adding missing feature LotShape_IR2\n",
      "Adding missing feature LotShape_IR3\n",
      "Adding missing feature MSZoning_C (all)\n",
      "Adding missing feature MSZoning_RH\n",
      "Adding missing feature MasVnrType_BrkCmn\n",
      "Adding missing feature MiscFeature_Gar2\n",
      "Adding missing feature MiscFeature_Othr\n",
      "Adding missing feature MiscFeature_TenC\n",
      "Adding missing feature Neighborhood_Blmngtn\n",
      "Adding missing feature Neighborhood_Blueste\n",
      "Adding missing feature Neighborhood_BrDale\n",
      "Adding missing feature Neighborhood_ClearCr\n",
      "Adding missing feature Neighborhood_IDOTRR\n",
      "Adding missing feature Neighborhood_MeadowV\n",
      "Adding missing feature Neighborhood_NPkVill\n",
      "Adding missing feature Neighborhood_NoRidge\n",
      "Adding missing feature Neighborhood_SWISU\n",
      "Adding missing feature Neighborhood_SawyerW\n",
      "Adding missing feature Neighborhood_StoneBr\n",
      "Adding missing feature Neighborhood_Timber\n",
      "Adding missing feature Neighborhood_Veenker\n",
      "Adding missing feature PavedDrive_N\n",
      "Adding missing feature PoolQC_Ex\n",
      "Adding missing feature PoolQC_Fa\n",
      "Adding missing feature PoolQC_Gd\n",
      "Adding missing feature RoofMatl_ClyTile\n",
      "Adding missing feature RoofMatl_Membran\n",
      "Adding missing feature RoofMatl_Metal\n",
      "Adding missing feature RoofMatl_Roll\n",
      "Adding missing feature RoofMatl_Tar&Grv\n",
      "Adding missing feature RoofMatl_WdShake\n",
      "Adding missing feature RoofMatl_WdShngl\n",
      "Adding missing feature RoofStyle_Flat\n",
      "Adding missing feature RoofStyle_Gambrel\n",
      "Adding missing feature RoofStyle_Mansard\n",
      "Adding missing feature RoofStyle_Shed\n",
      "Adding missing feature SaleCondition_Abnorml\n",
      "Adding missing feature SaleCondition_AdjLand\n",
      "Adding missing feature SaleCondition_Alloca\n",
      "Adding missing feature SaleCondition_Family\n",
      "Adding missing feature SaleType_COD\n",
      "Adding missing feature SaleType_CWD\n",
      "Adding missing feature SaleType_Con\n",
      "Adding missing feature SaleType_ConLD\n",
      "Adding missing feature SaleType_ConLI\n",
      "Adding missing feature SaleType_ConLw\n",
      "Adding missing feature SaleType_Oth\n",
      "Adding missing feature Street_Grvl\n",
      "Adding missing feature Utilities_NoSeWa\n",
      "(20, 258)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3816\\915363927.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predictDataCat[col] = 0\n"
     ]
    }
   ],
   "source": [
    "predictDataCat = pd.get_dummies(predictData.select_dtypes(include=['object']).copy())\n",
    "for col in categorical_data.columns:\n",
    "    if col not in predictDataCat.columns:\n",
    "        print(\"Adding missing feature {}\".format(col))\n",
    "        predictDataCat[col] = 0\n",
    "        \n",
    "print(predictDataCat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "executionInfo": {
     "elapsed": 3311,
     "status": "ok",
     "timestamp": 1601471535236,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "T2VNibHF5WmO",
    "outputId": "45d1ef07-f095-42ad-8db6-2d0de350f1f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
      "0   2.186679 -0.704939   4.358899     -0.904534    2.304486   -0.430482   \n",
      "1   0.046885 -0.704939  -0.229416     -0.904534    0.445439   -0.430482   \n",
      "2  -0.555701  0.995354  -0.229416      0.603023   -0.274437   -0.003686   \n",
      "3   0.621801  1.151732  -0.229416      0.603023   -1.070089   -0.430482   \n",
      "4  -1.145989 -0.704939  -0.229416     -2.412091    0.690449   -0.430482   \n",
      "5  -0.598743  1.730080  -0.229416      0.603023    0.862209   -0.430482   \n",
      "6  -0.826249 -0.704939  -0.229416     -0.904534   -1.070089   -0.430482   \n",
      "7   0.618726 -0.704939  -0.229416      0.603023   -1.070089   -0.430482   \n",
      "8  -0.946152 -0.704939  -0.229416      0.603023   -0.597749    2.002255   \n",
      "9  -0.100687 -0.704939  -0.229416      0.603023    0.427758   -0.430482   \n",
      "10 -0.002306  1.454558  -0.229416      0.603023    1.655335   -0.430482   \n",
      "11 -1.305859  0.660260  -0.229416     -0.904534   -1.070089   -0.430482   \n",
      "12  1.098335 -0.704939  -0.229416      0.603023   -1.070089   -0.430482   \n",
      "13 -0.457319 -0.704939  -0.229416     -0.904534    0.311567   -0.430482   \n",
      "14  0.000769 -0.704939  -0.229416     -0.904534   -0.034478   -0.430482   \n",
      "15 -0.823175  1.017694  -0.229416      0.603023   -1.070089   -0.430482   \n",
      "16  2.620172 -0.704939  -0.229416      0.603023    0.925356    0.201952   \n",
      "17 -0.100687  2.154533  -0.229416      2.110579   -0.375472   -0.430482   \n",
      "18 -0.438873 -0.704939  -0.229416     -0.904534   -0.946321    3.562000   \n",
      "19  0.108373 -0.704939  -0.229416      0.603023    1.026391    0.694707   \n",
      "\n",
      "    BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch  ...  OverallCond  \\\n",
      "0       0.904534           0.0   0.144276      -0.475514  ...    -0.800499   \n",
      "1       0.904534           0.0  -0.487072       1.560563  ...     1.083028   \n",
      "2      -1.105542           0.0  -0.927237       2.307984  ...     0.141264   \n",
      "3      -1.105542           0.0   0.126492      -0.475514  ...     1.083028   \n",
      "4       0.904534           0.0  -0.844984      -0.475514  ...    -0.800499   \n",
      "5       0.904534           0.0  -0.620455      -0.475514  ...    -0.800499   \n",
      "6      -1.105542           0.0   0.935685      -0.475514  ...     0.141264   \n",
      "7      -1.105542           0.0   1.980521      -0.475514  ...    -0.800499   \n",
      "8       0.904534           0.0  -1.180665       2.771900  ...    -0.800499   \n",
      "9      -1.105542           0.0   0.142053      -0.475514  ...     1.083028   \n",
      "10      0.904534           0.0  -0.867214      -0.475514  ...    -0.800499   \n",
      "11     -1.105542           0.0   0.064246      -0.475514  ...     1.083028   \n",
      "12     -1.105542           0.0   2.316203      -0.475514  ...    -0.800499   \n",
      "13      0.904534           0.0  -1.180665      -0.475514  ...    -0.800499   \n",
      "14      0.904534           0.0   0.622234      -0.475514  ...    -0.800499   \n",
      "15     -1.105542           0.0   0.937908      -0.475514  ...    -0.800499   \n",
      "16      0.904534           0.0   0.128715      -0.475514  ...     0.141264   \n",
      "17     -1.105542           0.0   0.768955      -0.475514  ...     2.966554   \n",
      "18      0.904534           0.0  -1.180665       0.967781  ...     0.141264   \n",
      "19      0.904534           0.0  -0.878330      -0.475514  ...     0.141264   \n",
      "\n",
      "    OverallQual  PoolArea  ScreenPorch  TotRmsAbvGrd  TotalBsmtSF  WoodDeckSF  \\\n",
      "0      1.179536       0.0    -0.229416      0.218870     2.374940   -0.718963   \n",
      "1     -0.294884       0.0    -0.229416     -0.328305    -0.421365   -0.718963   \n",
      "2      0.442326       0.0    -0.229416     -0.328305    -1.443935   -0.718963   \n",
      "3     -0.294884       0.0    -0.229416      2.407573    -1.309603    1.478718   \n",
      "4     -0.294884       0.0    -0.229416     -1.969832    -0.596819    0.040792   \n",
      "5      2.653955       0.0    -0.229416      1.860397    -0.133510    0.137674   \n",
      "6     -0.294884       0.0     4.358899     -1.422657    -0.311706   -0.718963   \n",
      "7      0.442326       0.0    -0.229416      0.218870     0.976788    0.260050   \n",
      "8     -0.294884       0.0    -0.229416     -0.328305    -0.690029   -0.718963   \n",
      "9     -1.032094       0.0    -0.229416     -0.328305     0.335282    0.611883   \n",
      "10     1.179536       0.0    -0.229416      0.766046     0.423010   -0.718963   \n",
      "11    -1.769303       0.0    -0.229416     -0.328305    -1.386364    0.137674   \n",
      "12     1.179536       0.0    -0.229416      0.218870     1.390751   -0.718963   \n",
      "13    -1.032094       0.0    -0.229416     -0.875481    -1.422003   -0.718963   \n",
      "14     0.442326       0.0    -0.229416     -0.328305     0.425751   -0.718963   \n",
      "15    -0.294884       0.0    -0.229416      0.218870    -0.308964   -0.718963   \n",
      "16    -0.294884       0.0    -0.229416      0.218870     1.305765    1.060598   \n",
      "17     0.442326       0.0    -0.229416      1.313222     0.236589   -0.718963   \n",
      "18    -1.032094       0.0    -0.229416     -0.875481     0.033720    1.147281   \n",
      "19    -1.032094       0.0    -0.229416     -0.328305     0.521703    3.033922   \n",
      "\n",
      "    YearBuilt  YearRemodAdd    YrSold  \n",
      "0    1.056742      0.916534 -0.236433  \n",
      "1   -0.530705      0.226979  1.339788  \n",
      "2    0.154076     -0.749892 -1.024544  \n",
      "3   -1.620130      0.112053 -0.236433  \n",
      "4    0.932236      0.686682 -0.236433  \n",
      "5    1.056742      0.916534  0.551677  \n",
      "6   -1.806888     -2.416318  0.551677  \n",
      "7    0.932236      0.686682 -1.024544  \n",
      "8   -0.250568     -1.496910 -1.024544  \n",
      "9   -0.375073     -1.726762  1.339788  \n",
      "10   0.652098      0.226979 -1.024544  \n",
      "11  -1.993647      0.456831 -1.024544  \n",
      "12   1.056742      0.973997  0.551677  \n",
      "13   0.963363      0.744145 -1.812654  \n",
      "14   0.932236      0.744145  0.551677  \n",
      "15   0.776604      0.456831 -1.024544  \n",
      "16   0.122949     -0.232725  1.339788  \n",
      "17  -1.028728      0.801608  1.339788  \n",
      "18  -0.748590      0.226979  1.339788  \n",
      "19  -0.281694     -1.554373 -0.236433  \n",
      "\n",
      "[20 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Standard Scale numerial feature data\n",
    "numericData = predictData.select_dtypes(include=['float64', 'int64']).copy()\n",
    "data_tmp = numericData.values # Returns a numpy array\n",
    "std_scaler = StandardScaler()\n",
    "data_tmp = std_scaler.fit_transform(data_tmp)\n",
    "numericData = pd.DataFrame(data_tmp, columns=numericData.columns)\n",
    "print(numericData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 3307,
     "status": "ok",
     "timestamp": 1601471535236,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "_kTEG9Ay5cN4",
    "outputId": "68fd5b94-a8eb-4b04-d772-a602251205df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict data final shape: (20, 294)\n"
     ]
    }
   ],
   "source": [
    "predictDataFinal = pd.concat([numericData, predictDataCat], axis=1)\n",
    "print('Predict data final shape: {}'.format(predictDataFinal.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "executionInfo": {
     "elapsed": 3303,
     "status": "ok",
     "timestamp": 1601471535237,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "iAh8zyZMzbGU",
    "outputId": "f3c6202d-b33c-4d12-c7ac-169e6f994d1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n",
      "[[271945.56 ]\n",
      " [111734.086]\n",
      " [197011.03 ]\n",
      " [336244.16 ]\n",
      " [136321.94 ]\n",
      " [308384.66 ]\n",
      " [159660.92 ]\n",
      " [261862.1  ]\n",
      " [136014.62 ]\n",
      " [127326.48 ]\n",
      " [267854.94 ]\n",
      " [224221.84 ]\n",
      " [362320.47 ]\n",
      " [146006.05 ]\n",
      " [185724.97 ]\n",
      " [248407.88 ]\n",
      " [134913.53 ]\n",
      " [279698.47 ]\n",
      " [122113.83 ]\n",
      " [216796.67 ]]\n"
     ]
    }
   ],
   "source": [
    "result = network.predict(predictDataFinal)\n",
    "result = y_scaler.inverse_transform(result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_SCALAR_UPRANKING_ON',\n",
       " '_TF_MODULE_IGNORED_PROPERTIES',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_activity_regularizer',\n",
       " '_add_trackable',\n",
       " '_add_trackable_child',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_assert_compile_was_called',\n",
       " '_assert_weights_created',\n",
       " '_auto_track_sub_layers',\n",
       " '_autocast',\n",
       " '_autographed_call',\n",
       " '_base_model_initialized',\n",
       " '_build_graph_network_for_inferred_shape',\n",
       " '_build_input_shape',\n",
       " '_call_accepts_kwargs',\n",
       " '_call_arg_was_passed',\n",
       " '_call_fn_arg_defaults',\n",
       " '_call_fn_arg_positions',\n",
       " '_call_fn_args',\n",
       " '_call_full_argspec',\n",
       " '_callable_losses',\n",
       " '_captured_weight_regularizer',\n",
       " '_cast_single_input',\n",
       " '_check_call_args',\n",
       " '_check_sample_weight_warning',\n",
       " '_checkpoint',\n",
       " '_checkpoint_dependencies',\n",
       " '_clear_losses',\n",
       " '_cluster_coordinator',\n",
       " '_compile_was_called',\n",
       " '_compiled_trainable_state',\n",
       " '_compute_dtype',\n",
       " '_compute_dtype_object',\n",
       " '_compute_output_and_mask_jointly',\n",
       " '_compute_tensor_usage_count',\n",
       " '_configure_steps_per_execution',\n",
       " '_conform_to_reference_input',\n",
       " '_created_nodes',\n",
       " '_dedup_weights',\n",
       " '_default_training_arg',\n",
       " '_deferred_dependencies',\n",
       " '_delete_tracking',\n",
       " '_deserialization_dependencies',\n",
       " '_deserialize_from_proto',\n",
       " '_distribution_strategy',\n",
       " '_dtype',\n",
       " '_dtype_policy',\n",
       " '_dynamic',\n",
       " '_eager_losses',\n",
       " '_enable_dict_to_input_mapping',\n",
       " '_expects_mask_arg',\n",
       " '_expects_training_arg',\n",
       " '_export_to_saved_model_graph',\n",
       " '_feed_input_names',\n",
       " '_feed_input_shapes',\n",
       " '_feed_inputs',\n",
       " '_flatten',\n",
       " '_flatten_layers',\n",
       " '_flatten_modules',\n",
       " '_flatten_to_reference_inputs',\n",
       " '_functional_construction_call',\n",
       " '_gather_children_attribute',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_get_call_arg_value',\n",
       " '_get_callback_model',\n",
       " '_get_cell_name',\n",
       " '_get_compile_args',\n",
       " '_get_existing_metric',\n",
       " '_get_input_masks',\n",
       " '_get_legacy_saved_model_children',\n",
       " '_get_node_attribute_at_index',\n",
       " '_get_optimizer',\n",
       " '_get_save_spec',\n",
       " '_get_trainable_state',\n",
       " '_get_unnested_name_scope',\n",
       " '_graph_initialized',\n",
       " '_graph_network_add_loss',\n",
       " '_graph_network_add_metric',\n",
       " '_handle_activity_regularization',\n",
       " '_handle_deferred_dependencies',\n",
       " '_handle_deferred_layer_dependencies',\n",
       " '_handle_weight_regularization',\n",
       " '_has_explicit_input_shape',\n",
       " '_in_multi_worker_mode',\n",
       " '_inbound_nodes',\n",
       " '_inbound_nodes_value',\n",
       " '_infer_output_signature',\n",
       " '_inferred_input_shape',\n",
       " '_init_batch_counters',\n",
       " '_init_call_fn_args',\n",
       " '_init_graph_network',\n",
       " '_init_set_name',\n",
       " '_initial_weights',\n",
       " '_input_coordinates',\n",
       " '_input_dtype',\n",
       " '_input_layers',\n",
       " '_input_spec',\n",
       " '_insert_layers',\n",
       " '_instrument_layer_creation',\n",
       " '_instrumented_keras_api',\n",
       " '_instrumented_keras_layer_class',\n",
       " '_instrumented_keras_model_class',\n",
       " '_is_compiled',\n",
       " '_is_graph_network',\n",
       " '_is_layer',\n",
       " '_is_layer_name_unique',\n",
       " '_is_model_for_instrumentation',\n",
       " '_jit_compile',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " '_keras_tensor_symbolic_call',\n",
       " '_layer_call_argspecs',\n",
       " '_layer_checkpoint_dependencies',\n",
       " '_layout_map',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_losses',\n",
       " '_map_resources',\n",
       " '_maybe_build',\n",
       " '_maybe_cast_inputs',\n",
       " '_maybe_create_attribute',\n",
       " '_maybe_initialize_trackable',\n",
       " '_maybe_load_initial_epoch_from_ckpt',\n",
       " '_maybe_load_initial_step_from_ckpt',\n",
       " '_metrics',\n",
       " '_metrics_lock',\n",
       " '_must_restore_from_config',\n",
       " '_name',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_name_scope',\n",
       " '_name_scope_on_declaration',\n",
       " '_nested_inputs',\n",
       " '_nested_outputs',\n",
       " '_network_nodes',\n",
       " '_no_dependency',\n",
       " '_nodes_by_depth',\n",
       " '_non_trainable_weights',\n",
       " '_obj_reference_counts',\n",
       " '_obj_reference_counts_dict',\n",
       " '_object_identifier',\n",
       " '_outbound_nodes',\n",
       " '_outbound_nodes_value',\n",
       " '_output_coordinates',\n",
       " '_output_layers',\n",
       " '_output_mask_cache',\n",
       " '_output_shape_cache',\n",
       " '_output_tensor_cache',\n",
       " '_predict_counter',\n",
       " '_preload_simple_restoration',\n",
       " '_preserve_input_structure_in_config',\n",
       " '_reset_compile_cache',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_restore_from_tensors',\n",
       " '_run_eagerly',\n",
       " '_run_internal_graph',\n",
       " '_saved_model_arg_spec',\n",
       " '_saved_model_inputs_spec',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_tracked_trackables',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_serialize_to_proto',\n",
       " '_serialize_to_tensors',\n",
       " '_set_call_arg_value',\n",
       " '_set_connectivity_metadata',\n",
       " '_set_dtype_policy',\n",
       " '_set_inputs',\n",
       " '_set_mask_keras_history_checked',\n",
       " '_set_mask_metadata',\n",
       " '_set_output_names',\n",
       " '_set_save_spec',\n",
       " '_set_trainable_state',\n",
       " '_set_training_mode',\n",
       " '_setattr_tracking',\n",
       " '_should_cast_single_input',\n",
       " '_should_compute_mask',\n",
       " '_should_eval',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_split_out_first_arg',\n",
       " '_stateful',\n",
       " '_steps_per_execution',\n",
       " '_supports_masking',\n",
       " '_tensor_usage_count',\n",
       " '_test_counter',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_thread_local',\n",
       " '_track_trackable',\n",
       " '_trackable_children',\n",
       " '_trackable_saved_model_saver',\n",
       " '_tracking_metadata',\n",
       " '_train_counter',\n",
       " '_trainable',\n",
       " '_trainable_weights',\n",
       " '_training_state',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_undeduplicated_weights',\n",
       " '_update_uid',\n",
       " '_updated_config',\n",
       " '_updates',\n",
       " '_use_input_spec_as_call_signature',\n",
       " '_use_legacy_deferred_behavior',\n",
       " '_validate_compile',\n",
       " '_validate_graph_inputs_and_outputs',\n",
       " '_validate_target_and_loss',\n",
       " 'activity_regularizer',\n",
       " 'add',\n",
       " 'add_loss',\n",
       " 'add_metric',\n",
       " 'add_update',\n",
       " 'add_variable',\n",
       " 'add_weight',\n",
       " 'build',\n",
       " 'built',\n",
       " 'call',\n",
       " 'compile',\n",
       " 'compiled_loss',\n",
       " 'compiled_metrics',\n",
       " 'compute_dtype',\n",
       " 'compute_loss',\n",
       " 'compute_mask',\n",
       " 'compute_metrics',\n",
       " 'compute_output_shape',\n",
       " 'compute_output_signature',\n",
       " 'count_params',\n",
       " 'distribute_strategy',\n",
       " 'dtype',\n",
       " 'dtype_policy',\n",
       " 'dynamic',\n",
       " 'evaluate',\n",
       " 'evaluate_generator',\n",
       " 'finalize_state',\n",
       " 'fit',\n",
       " 'fit_generator',\n",
       " 'from_config',\n",
       " 'get_config',\n",
       " 'get_input_at',\n",
       " 'get_input_mask_at',\n",
       " 'get_input_shape_at',\n",
       " 'get_layer',\n",
       " 'get_output_at',\n",
       " 'get_output_mask_at',\n",
       " 'get_output_shape_at',\n",
       " 'get_weights',\n",
       " 'history',\n",
       " 'inbound_nodes',\n",
       " 'input',\n",
       " 'input_mask',\n",
       " 'input_names',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'inputs',\n",
       " 'layers',\n",
       " 'load_weights',\n",
       " 'loss',\n",
       " 'losses',\n",
       " 'make_predict_function',\n",
       " 'make_test_function',\n",
       " 'make_train_function',\n",
       " 'metrics',\n",
       " 'metrics_names',\n",
       " 'name',\n",
       " 'name_scope',\n",
       " 'non_trainable_variables',\n",
       " 'non_trainable_weights',\n",
       " 'optimizer',\n",
       " 'outbound_nodes',\n",
       " 'output',\n",
       " 'output_mask',\n",
       " 'output_names',\n",
       " 'output_shape',\n",
       " 'outputs',\n",
       " 'pop',\n",
       " 'predict',\n",
       " 'predict_function',\n",
       " 'predict_generator',\n",
       " 'predict_on_batch',\n",
       " 'predict_step',\n",
       " 'reset_metrics',\n",
       " 'reset_states',\n",
       " 'run_eagerly',\n",
       " 'save',\n",
       " 'save_spec',\n",
       " 'save_weights',\n",
       " 'set_weights',\n",
       " 'state_updates',\n",
       " 'stateful',\n",
       " 'stop_training',\n",
       " 'submodules',\n",
       " 'summary',\n",
       " 'supports_masking',\n",
       " 'test_function',\n",
       " 'test_on_batch',\n",
       " 'test_step',\n",
       " 'to_json',\n",
       " 'to_yaml',\n",
       " 'train_function',\n",
       " 'train_on_batch',\n",
       " 'train_step',\n",
       " 'train_tf_function',\n",
       " 'trainable',\n",
       " 'trainable_variables',\n",
       " 'trainable_weights',\n",
       " 'updates',\n",
       " 'variable_dtype',\n",
       " 'variables',\n",
       " 'weights',\n",
       " 'with_name_scope']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(294, 1) dtype=float32, numpy=\n",
       " array([[-0.03414702],\n",
       "        [ 0.01442533],\n",
       "        [ 0.01900642],\n",
       "        [-0.01135246],\n",
       "        [-0.01823618],\n",
       "        [ 0.01107969],\n",
       "        [ 0.04903196],\n",
       "        [ 0.02251063],\n",
       "        [ 0.00372783],\n",
       "        [ 0.01088816],\n",
       "        [-0.00295071],\n",
       "        [ 0.06887724],\n",
       "        [ 0.0200751 ],\n",
       "        [ 0.05483748],\n",
       "        [-0.05801459],\n",
       "        [ 0.10308452],\n",
       "        [ 0.03155214],\n",
       "        [-0.05563816],\n",
       "        [ 0.03630697],\n",
       "        [-0.01666955],\n",
       "        [ 0.00260653],\n",
       "        [-0.01665299],\n",
       "        [ 0.0313839 ],\n",
       "        [ 0.01937352],\n",
       "        [ 0.00593704],\n",
       "        [-0.00475255],\n",
       "        [ 0.07101125],\n",
       "        [ 0.125204  ],\n",
       "        [ 0.00295833],\n",
       "        [ 0.01876202],\n",
       "        [ 0.06132696],\n",
       "        [ 0.03927292],\n",
       "        [ 0.0281894 ],\n",
       "        [ 0.09419944],\n",
       "        [-0.00806894],\n",
       "        [-0.00921244],\n",
       "        [-0.12072087],\n",
       "        [-0.05715486],\n",
       "        [ 0.04631723],\n",
       "        [-0.02131969],\n",
       "        [-0.0441886 ],\n",
       "        [ 0.00726535],\n",
       "        [-0.12510385],\n",
       "        [-0.07589511],\n",
       "        [ 0.07996278],\n",
       "        [ 0.08587211],\n",
       "        [-0.14409974],\n",
       "        [ 0.0993235 ],\n",
       "        [ 0.02274279],\n",
       "        [ 0.13391426],\n",
       "        [ 0.00853497],\n",
       "        [-0.04452438],\n",
       "        [ 0.06271946],\n",
       "        [-0.00682985],\n",
       "        [ 0.00209701],\n",
       "        [ 0.02835157],\n",
       "        [-0.06359597],\n",
       "        [-0.08216022],\n",
       "        [-0.02149637],\n",
       "        [-0.07868858],\n",
       "        [-0.11758857],\n",
       "        [-0.18617468],\n",
       "        [-0.07265663],\n",
       "        [-0.06248046],\n",
       "        [-0.0782884 ],\n",
       "        [-0.09572981],\n",
       "        [ 0.09723549],\n",
       "        [ 0.0081256 ],\n",
       "        [-0.09922834],\n",
       "        [ 0.07146787],\n",
       "        [-0.06511725],\n",
       "        [-0.08686285],\n",
       "        [-0.09043374],\n",
       "        [-0.06475636],\n",
       "        [-0.15084596],\n",
       "        [-0.00976849],\n",
       "        [-0.05222455],\n",
       "        [-0.05738507],\n",
       "        [-0.23312113],\n",
       "        [-0.0610713 ],\n",
       "        [-0.09941728],\n",
       "        [-0.04889355],\n",
       "        [-0.02058383],\n",
       "        [-0.166652  ],\n",
       "        [-0.06617624],\n",
       "        [-0.09259709],\n",
       "        [-0.20264873],\n",
       "        [-0.00804903],\n",
       "        [-0.04445478],\n",
       "        [-0.1889609 ],\n",
       "        [-0.02654918],\n",
       "        [-0.199569  ],\n",
       "        [ 0.01375844],\n",
       "        [ 0.02446459],\n",
       "        [-0.11473893],\n",
       "        [-0.03207333],\n",
       "        [ 0.05685644],\n",
       "        [-0.12462076],\n",
       "        [-0.10316411],\n",
       "        [-0.09733521],\n",
       "        [-0.11264979],\n",
       "        [-0.11146957],\n",
       "        [-0.12280392],\n",
       "        [ 0.08860145],\n",
       "        [ 0.1264033 ],\n",
       "        [ 0.16134486],\n",
       "        [-0.05091155],\n",
       "        [ 0.08782173],\n",
       "        [-0.06491442],\n",
       "        [ 0.12934692],\n",
       "        [-0.11072978],\n",
       "        [ 0.04419828],\n",
       "        [-0.00737963],\n",
       "        [-0.0457661 ],\n",
       "        [ 0.07156467],\n",
       "        [-0.0485579 ],\n",
       "        [-0.03678327],\n",
       "        [-0.14711101],\n",
       "        [ 0.18850322],\n",
       "        [-0.15118338],\n",
       "        [-0.02422555],\n",
       "        [-0.00379626],\n",
       "        [-0.06575098],\n",
       "        [-0.00565285],\n",
       "        [-0.02590416],\n",
       "        [ 0.0532601 ],\n",
       "        [-0.16479634],\n",
       "        [-0.10331055],\n",
       "        [ 0.00664852],\n",
       "        [-0.18427901],\n",
       "        [-0.11523386],\n",
       "        [ 0.00457278],\n",
       "        [-0.08528358],\n",
       "        [-0.09578145],\n",
       "        [ 0.01666114],\n",
       "        [-0.01496272],\n",
       "        [-0.04662934],\n",
       "        [-0.01234535],\n",
       "        [ 0.09991558],\n",
       "        [ 0.10259276],\n",
       "        [ 0.04601043],\n",
       "        [ 0.0054439 ],\n",
       "        [-0.0189118 ],\n",
       "        [ 0.05264042],\n",
       "        [ 0.00238202],\n",
       "        [-0.05219629],\n",
       "        [ 0.00049182],\n",
       "        [ 0.01130864],\n",
       "        [ 0.12489507],\n",
       "        [-0.08814445],\n",
       "        [-0.12161654],\n",
       "        [-0.07003215],\n",
       "        [-0.01291876],\n",
       "        [-0.10956597],\n",
       "        [-0.01516553],\n",
       "        [-0.00894524],\n",
       "        [ 0.01476099],\n",
       "        [ 0.03461444],\n",
       "        [-0.0029381 ],\n",
       "        [ 0.01058498],\n",
       "        [-0.05045917],\n",
       "        [ 0.03508119],\n",
       "        [-0.0418114 ],\n",
       "        [-0.10110876],\n",
       "        [-0.1042179 ],\n",
       "        [ 0.13807319],\n",
       "        [-0.0287176 ],\n",
       "        [ 0.17565213],\n",
       "        [-0.15008174],\n",
       "        [ 0.08946282],\n",
       "        [-0.11764666],\n",
       "        [-0.05020628],\n",
       "        [-0.09566019],\n",
       "        [-0.02636979],\n",
       "        [-0.02771776],\n",
       "        [-0.0581516 ],\n",
       "        [-0.07416303],\n",
       "        [-0.1701571 ],\n",
       "        [-0.09402587],\n",
       "        [-0.24507795],\n",
       "        [-0.02846481],\n",
       "        [-0.18541436],\n",
       "        [-0.11746106],\n",
       "        [-0.05457526],\n",
       "        [-0.12481829],\n",
       "        [-0.02139814],\n",
       "        [-0.11237958],\n",
       "        [-0.05204167],\n",
       "        [-0.01386061],\n",
       "        [ 0.03197765],\n",
       "        [-0.01565862],\n",
       "        [-0.10125966],\n",
       "        [-0.02733984],\n",
       "        [-0.0732787 ],\n",
       "        [-0.05939914],\n",
       "        [ 0.06683655],\n",
       "        [-0.13211957],\n",
       "        [-0.05992337],\n",
       "        [-0.0769774 ],\n",
       "        [-0.0103976 ],\n",
       "        [ 0.04015788],\n",
       "        [-0.0464997 ],\n",
       "        [ 0.06140396],\n",
       "        [ 0.02884573],\n",
       "        [ 0.10310479],\n",
       "        [-0.01650572],\n",
       "        [ 0.02555348],\n",
       "        [ 0.09592445],\n",
       "        [-0.05482202],\n",
       "        [-0.03977546],\n",
       "        [ 0.01822025],\n",
       "        [ 0.0165945 ],\n",
       "        [ 0.02036227],\n",
       "        [-0.01770454],\n",
       "        [-0.00096782],\n",
       "        [-0.202642  ],\n",
       "        [ 0.02419311],\n",
       "        [ 0.04265333],\n",
       "        [ 0.07302579],\n",
       "        [-0.06098729],\n",
       "        [-0.00386583],\n",
       "        [ 0.04091575],\n",
       "        [ 0.02479721],\n",
       "        [ 0.06964519],\n",
       "        [-0.17506911],\n",
       "        [-0.01632298],\n",
       "        [-0.00169441],\n",
       "        [-0.08189034],\n",
       "        [-0.13896133],\n",
       "        [-0.12067544],\n",
       "        [ 0.09020942],\n",
       "        [-0.14376226],\n",
       "        [ 0.08661611],\n",
       "        [ 0.03647655],\n",
       "        [-0.08384077],\n",
       "        [ 0.18904302],\n",
       "        [-0.05973636],\n",
       "        [-0.15451084],\n",
       "        [-0.03208928],\n",
       "        [-0.1991548 ],\n",
       "        [-0.02326401],\n",
       "        [-0.11941516],\n",
       "        [-0.00381272],\n",
       "        [-0.11120363],\n",
       "        [ 0.08668618],\n",
       "        [-0.0026289 ],\n",
       "        [ 0.06844925],\n",
       "        [-0.13858229],\n",
       "        [ 0.01887161],\n",
       "        [-0.01847845],\n",
       "        [ 0.04687321],\n",
       "        [ 0.20662996],\n",
       "        [-0.07959947],\n",
       "        [ 0.06084662],\n",
       "        [-0.0318664 ],\n",
       "        [-0.05087063],\n",
       "        [ 0.03630203],\n",
       "        [ 0.12239614],\n",
       "        [-0.16509171],\n",
       "        [-0.00686913],\n",
       "        [-0.00324373],\n",
       "        [-0.23086102],\n",
       "        [-0.09817091],\n",
       "        [ 0.10527773],\n",
       "        [ 0.13589792],\n",
       "        [-0.01806612],\n",
       "        [-0.173647  ],\n",
       "        [ 0.01011481],\n",
       "        [ 0.1309247 ],\n",
       "        [-0.05558151],\n",
       "        [-0.05108248],\n",
       "        [-0.03505043],\n",
       "        [-0.09242442],\n",
       "        [ 0.01534608],\n",
       "        [ 0.03612038],\n",
       "        [-0.11295193],\n",
       "        [ 0.01005216],\n",
       "        [-0.09324773],\n",
       "        [-0.08519093],\n",
       "        [-0.00807283],\n",
       "        [-0.03538996],\n",
       "        [-0.06901493],\n",
       "        [ 0.08910626],\n",
       "        [-0.04024681],\n",
       "        [-0.00095731],\n",
       "        [-0.10967792],\n",
       "        [-0.15764755],\n",
       "        [-0.04040443],\n",
       "        [-0.01084431],\n",
       "        [-0.09093709],\n",
       "        [-0.12346472],\n",
       "        [-0.11566494],\n",
       "        [-0.11051629],\n",
       "        [-0.04975973]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([-0.04051582], dtype=float32)>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TIPP-DL-LU03 Lab v2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
