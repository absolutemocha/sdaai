{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhS3gErdhjCp"
   },
   "source": [
    "# Deep Learning Fundamentals - LU03-B Lab Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Load the saved MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUk5kr2_hjCq"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('MNIST_data.pickle', 'rb') as in_file:\n",
    "    train_images, train_labels, test_images, test_labels = pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-6CsDsq-nEA"
   },
   "source": [
    "## 3.7 Print the shape of train and test data for verification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "executionInfo": {
     "elapsed": 902,
     "status": "ok",
     "timestamp": 1601520126721,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "CzMoRLjU-Ida",
    "outputId": "cece747c-a6c9-472b-8f8d-64aad6bd2399"
   },
   "outputs": [],
   "source": [
    "print(\"Train images shape: {}\".format(train_images.shape))\n",
    "print(\"Train labels shape: {}\".format(train_labels.shape))\n",
    "print(\"Test images shape: {}\".format(test_images.shape))\n",
    "print(\"Test labels shape: {}\".format(test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAgRD3X3hjCv"
   },
   "source": [
    "## 3.8 Build and train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "\n",
    "def classifier_model():\n",
    "    network = models.Sequential()\n",
    "    network.add(layers.Dense(128, activation='relu', input_shape=(784,)))\n",
    "    network.add(layers.Dense(64, activation='relu'))\n",
    "    network.add(layers.Dense(10, activation='softmax'))\n",
    "    return network\n",
    "\n",
    "model = classifier_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.1 Optimizers\n",
    "\n",
    "In this section, you will explore the different optimizers on the training performance. Try to change the learning rate as well.\n",
    "\n",
    "Refer to https://www.tensorflow.org/api_docs/python/tf/keras/optimizers for the available optimizers in Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 764
    },
    "executionInfo": {
     "elapsed": 13690,
     "status": "ok",
     "timestamp": 1601520160928,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "imvo-7u7hjCv",
    "outputId": "6447ded7-9ec3-42c2-c050-5b7f6ec0f146",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy.random as nr\n",
    "\n",
    "nr.seed(1305)\n",
    "\n",
    "# Define the optimizer list (Feel free to change to other optimizers)\n",
    "optimizers = ['SGD', 'RMSprop', 'adam']\n",
    "history_cache = {}\n",
    "\n",
    "for opt in optimizers:\n",
    "    \n",
    "    # Define the model\n",
    "    model = classifier_model()\n",
    "\n",
    "    # Compile using different optimizer\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_images, train_labels, epochs=20, batch_size=128, validation_data=(test_images, test_labels))\n",
    "    history_cache[opt] = history\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "    print('\\nTest Acc ({}) - {:.4f}: \\n'.format(opt, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mK3OTKWhjC1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_loss(history_cache):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for opt, history in history_cache.items():\n",
    "        train_loss = history.history['loss']\n",
    "        test_loss = history.history['val_loss']\n",
    "        x = list(range(1, len(test_loss) + 1))\n",
    "        plt.plot(x, test_loss, label='Val loss - {}'.format(opt))\n",
    "        plt.plot(x, train_loss, label='Train loss - {}'.format(opt))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss over Epochs')\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_accuracy(history_cache):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for opt, history in history_cache.items():\n",
    "        train_acc = history.history['accuracy']\n",
    "        test_acc = history.history['val_accuracy']\n",
    "        x = list(range(1, len(test_acc) + 1))\n",
    "        plt.plot(x, test_acc, label='Val accuracy - {}'.format(opt))\n",
    "        plt.plot(x, train_acc, label='Train accuracy - {}'.format(opt))  \n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Accuracy over Epochs')  \n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 1210,
     "status": "ok",
     "timestamp": 1601385756299,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "c8-8RSq9hjC3",
    "outputId": "1aba491a-d412-485f-e974-efbf7ce31c9a"
   },
   "outputs": [],
   "source": [
    "plot_loss(history_cache)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 962,
     "status": "ok",
     "timestamp": 1601520182525,
     "user": {
      "displayName": "Shannen Ang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4dJOVMwcjFhPJEz7npDxgg-ASHzpFf5XkyU8jQ=s64",
      "userId": "04024065041896518848"
     },
     "user_tz": -480
    },
    "id": "JzoRePE7hjC5",
    "outputId": "64fe516e-cf3c-4ac5-c0f9-e1f87126a7cb"
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.2 Dropout\n",
    "\n",
    "In this section, you will include dropout into every layer in the model and explore different dropout rate on the training performance.\n",
    "\n",
    "Refer to https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_dropout_model(dropout_rate):\n",
    "    \"\"\"Classifier model with dropout in every layer.\n",
    "    \n",
    "    :param dropout_rate: The rate for dropout\n",
    "    :return: network\n",
    "    \"\"\"\n",
    "    assert dropout_rate <= 1, 'Incorrect dropout rate specified.'\n",
    "    network = models.Sequential()\n",
    "    # Your codes here\n",
    "    return network\n",
    "\n",
    "model = classifier_dropout_model(dropout_rate=0.2)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(1305)\n",
    "\n",
    "# Define the model\n",
    "model = classifier_dropout_model(dropout_rate=0)\n",
    "\n",
    "# Compile using different optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=20, batch_size=128, validation_data=(test_images, test_labels))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('\\nTest Acc: {:.4f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    train_loss = history.history['loss']\n",
    "    test_loss = history.history['val_loss']\n",
    "    x = list(range(1, len(test_loss) + 1))\n",
    "    plt.plot(x, test_loss, label='Val loss')\n",
    "    plt.plot(x, train_loss, label='Train loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_accuracy(history):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    train_acc = history.history['accuracy']\n",
    "    test_acc = history.history['val_accuracy']\n",
    "    x = list(range(1, len(test_acc) + 1))\n",
    "    plt.plot(x, test_acc, label='Val accuracy')\n",
    "    plt.plot(x, train_acc, label='Train accuracy')  \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy over Epochs')  \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.2 Batchnorm\n",
    "\n",
    "In this section, you will include batchnorm into every layer of the model and explore its impact on the training performance. Remember batchnorm are typically used before activation function. \n",
    "\n",
    "Refer to https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_batchnorm_model():\n",
    "    \"\"\"Classifier model with batch norm in every layer.\n",
    "    \n",
    "    :return: network\n",
    "    \"\"\"\n",
    "    network = models.Sequential()\n",
    "    # your codes here\n",
    "    return network\n",
    "\n",
    "model = classifier_batchnorm_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(1305)\n",
    "\n",
    "# Define the model\n",
    "model = classifier_batchnorm_model()\n",
    "\n",
    "# Compile using different optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=20, batch_size=128, validation_data=(test_images, test_labels))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('\\nTest Acc: {:.4f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.3 Weights Initialization\n",
    "\n",
    "In this section, you will change the weights initialization of every layer in the model and explore the differences on the training performance.\n",
    "\n",
    "Refer to https://www.tensorflow.org/api_docs/python/tf/keras/initializers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_diff_wts_init_model():\n",
    "    \"\"\"Classifier model with different weights initialization in every layer.\n",
    "    \n",
    "    :return: network\n",
    "    \"\"\"\n",
    "    network = models.Sequential()\n",
    "    # your codes here\n",
    "    return network\n",
    "\n",
    "model = classifier_diff_wts_init_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(1305)\n",
    "\n",
    "# Define the model\n",
    "model = classifier_diff_wts_init_model()\n",
    "\n",
    "# Compile using different optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=20, batch_size=128, validation_data=(test_images, test_labels))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('\\nTest Acc: {:.4f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.4 Regularization\n",
    "\n",
    "In this section, you will include the regularization in every layer in the model and explore the differences on the training performance.\n",
    "\n",
    "Refer to https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/Regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def classifier_reg_model(reg_type, lambd):\n",
    "    \"\"\"Classifier model with regularizations in every layer.\n",
    "    \n",
    "    :param reg_type: Regularization type\n",
    "    :param lambd: Regularization constant\n",
    "    :return: network\n",
    "    \"\"\"\n",
    "    assert reg_type in ['L1', 'L2'], 'Incorrect norm type specified'\n",
    "    if reg_type == 'L1':\n",
    "        reg = regularizers.L1(lambd)\n",
    "    elif reg_type == 'L2':\n",
    "        reg = regularizers.L2(lambd)\n",
    "    network = models.Sequential()\n",
    "    # your codes here\n",
    "    return network\n",
    "\n",
    "model = classifier_reg_model(reg_type='L1', lambd=0.1)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(1305)\n",
    "\n",
    "# Define the model\n",
    "model = classifier_reg_model(reg_type='L1', lambd=0.01)\n",
    "\n",
    "# Compile using different optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=20, batch_size=128, validation_data=(test_images, test_labels))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('\\nTest Acc: {:.4f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.5 Learning Rate Schedulers\n",
    "\n",
    "In this section, you will include the learning rate scheduler during the compilation and explore the differences on the training performance.\n",
    "\n",
    "Refer to https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_model():\n",
    "    \"\"\"Classifier model.\n",
    "\n",
    "    :return: network\n",
    "    \"\"\"\n",
    "    network = models.Sequential()\n",
    "    network.add(layers.Dense(128, activation='relu', input_shape=(784,)))\n",
    "    network.add(layers.Dense(64, activation='relu'))\n",
    "    network.add(layers.Dense(10, activation='softmax'))\n",
    "    return network\n",
    "\n",
    "model = classifier_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "nr.seed(1305)\n",
    "\n",
    "# Define the model\n",
    "model = classifier_model()\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "lr = 0.01\n",
    "lr_schedule = # Your codes here\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Compile using different optimizer\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=20, batch_size=128, validation_data=(test_images, test_labels))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('\\nTest Acc: {:.4f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2mOc_PShjC8"
   },
   "source": [
    "## 3.9 Save the trained model\n",
    "\n",
    "There are various ways of saving a trained model. The sections below depicts some common methods of saving the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ic15iWjoCLhW"
   },
   "source": [
    "### 3.9.1 Save to local drive using object method 'save'\n",
    "This method saves the model after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpOAGC4_hjC8"
   },
   "outputs": [],
   "source": [
    "model.save(\"MNIST_classifier_model_1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.2 Save to local drive using callback method\n",
    "This method saves the model every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = classifier_model()\n",
    "\n",
    "# Compile using adam optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set the callback\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(\"MNIST_classifier_model_2_{epoch:02d}.h5\", monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(train_images, train_labels, epochs=20, batch_size=128, validation_data=(test_images, test_labels), callbacks=[callback])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('\\nTest Acc: {:.4f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3QbZAwDCvd7"
   },
   "source": [
    "## 3.10 Your Exercise\n",
    "We will try to randomly select an image from the mnist database and perform a prediction using your custom model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10.1 Build and save your model\n",
    "\n",
    "Build your own model and integrate what you have learnt so far into your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqImR4KxC5HU"
   },
   "outputs": [],
   "source": [
    "# Your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIhqcqtcDuA5"
   },
   "source": [
    "Randomly select 1 of of the MNIST image for prediction. Display the label of your selected image for validation. You can either select from your train_labels, test_labels or from original mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flFnig8eDa8Q"
   },
   "outputs": [],
   "source": [
    "# Your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJRccVH9Tonv"
   },
   "source": [
    "Your prediction will show the probablities of all 10 values. Select the max probability to show the correct predicted value.\n",
    "<br>\n",
    "**HINT: use numpy.argmax(prediction)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFNBGCSFVq0I"
   },
   "outputs": [],
   "source": [
    "# Your codes here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TIPP-DL-LU04 Lab Part 2 v2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
