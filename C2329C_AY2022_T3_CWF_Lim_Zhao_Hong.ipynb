{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/absolutemocha/sdaai/blob/main/C2329C_AY2022_T3_CWF_Lim_Zhao_Hong.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81d187d1",
      "metadata": {
        "id": "81d187d1"
      },
      "source": [
        "# C2329C Machine Learning Fundamentals\n",
        "\n",
        "## Coursework Final\n",
        "***\n",
        "### Student Name: $<Lim Zhao Hong>$ \n",
        "### Student ID: $<20065320>$\n",
        "\n",
        "***\n",
        "\n",
        "## Features description from the $CleandDataV20210515.csv$ file:\n",
        "\n",
        "**index_col** time step for the washing cycle\n",
        "\n",
        "**avC:** average current \n",
        "\n",
        "**avP:** average power\n",
        "\n",
        "**avR:** average resistant\n",
        "\n",
        "**maxC:** maximum current \n",
        "\n",
        "**maxP:** maximum power\n",
        "\n",
        "**sdC:** standard deviation for current\n",
        "\n",
        "**sdP:** standard deviation for power\n",
        "\n",
        "**stdCR:** standard deviation for resistant\n",
        "\n",
        "**stdCP:** standard deviation for power\n",
        "\n",
        "**AvRR:** average relative resistance to previous resistance reading\n",
        "\n",
        "**mode:** positive class: Daily Wash | negative class: Not Daily Wash\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a4a8a70",
      "metadata": {
        "id": "7a4a8a70"
      },
      "outputs": [],
      "source": [
        "# Import necessary Python libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a770d865",
      "metadata": {
        "id": "a770d865"
      },
      "source": [
        "## Data Preparation Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b886be8",
      "metadata": {
        "id": "9b886be8"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "data_path = ['data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e87a9dd",
      "metadata": {
        "id": "0e87a9dd"
      },
      "outputs": [],
      "source": [
        "# Import the data using the file path\n",
        "filepath = os.sep.join(data_path + ['CleandDataV20210515.csv'])\n",
        "data = pd.read_csv(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a11baea5",
      "metadata": {
        "id": "a11baea5"
      },
      "outputs": [],
      "source": [
        "data.head(1).T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "QfO8TraNrJ4L"
      },
      "id": "QfO8TraNrJ4L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove extraneous columns\n",
        "data.drop(['state', 'area_code', 'phone_number'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "AlIrQDDsgp6y"
      },
      "id": "AlIrQDDsgp6y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "gEDGihIRhDop"
      },
      "id": "gEDGihIRhDop",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the relationship between the variables."
      ],
      "metadata": {
        "id": "Hg3ij8imxCw7"
      },
      "id": "Hg3ij8imxCw7"
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "sns.set_context('notebook')\n",
        "sns.set_palette('dark')\n",
        "sns.set_style('white')\n",
        "\n",
        "sns.pairplot(data);"
      ],
      "metadata": {
        "id": "y0zGD1aqw-uz"
      },
      "id": "y0zGD1aqw-uz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2051d116",
      "metadata": {
        "id": "2051d116"
      },
      "source": [
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1caf715",
      "metadata": {
        "id": "c1caf715"
      },
      "source": [
        "## K-Nearest Neigbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92dd0710",
      "metadata": {
        "id": "92dd0710"
      },
      "outputs": [],
      "source": [
        "#K-nearest neighbors requires scaled data. Scale the data using one of the scaling methods discussed in the lecture.\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "\n",
        "for col in ['mode']:\n",
        "    data[col] = lb.fit_transform(data[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0657169",
      "metadata": {
        "id": "b0657169"
      },
      "outputs": [],
      "source": [
        "# Mute the sklearn warning\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', module='sklearn')\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "msc = MinMaxScaler()\n",
        "\n",
        "data = pd.DataFrame(msc.fit_transform(data),  # this is an np.array, not a dataframe.\n",
        "                    columns=data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "318c7767",
      "metadata": {
        "id": "318c7767"
      },
      "outputs": [],
      "source": [
        "# Get a list of all the columns that don't contain the label\n",
        "x_cols = [x for x in data.columns if x != 'mode']\n",
        "\n",
        "# Split the data into two dataframes\n",
        "X_data = data[x_cols]\n",
        "y_data = data['mode']\n",
        "\n",
        "# # alternatively:\n",
        "# X_data = data.copy()\n",
        "# y_data = X_data.pop('mode')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, \n",
        "                                                    test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "knn = knn.fit(X_train, y_train)\n",
        "\n",
        "y_test_pred = knn.predict(X_test)"
      ],
      "metadata": {
        "id": "BPNzmB23pXmf"
      },
      "id": "BPNzmB23pXmf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the % of values that were correctly predicted\n",
        "\n",
        "def accuracy(real, predict):\n",
        "    return sum(real == predict) / float(real.shape[0])"
      ],
      "metadata": {
        "id": "tdwy1AJvprYI"
      },
      "id": "tdwy1AJvprYI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy(y_test, y_test_pred))"
      ],
      "metadata": {
        "id": "rBdgMJaipxvs"
      },
      "id": "rBdgMJaipxvs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas boxplot\n",
        "\n",
        "data.boxplot(by='mode');"
      ],
      "metadata": {
        "id": "--Mi4WkQtS1J"
      },
      "id": "--Mi4WkQtS1J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_context('mode')\n",
        "sns.pairplot(data, hue='species');"
      ],
      "metadata": {
        "id": "7-Ee7A74txsf"
      },
      "id": "7-Ee7A74txsf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ef737a52",
      "metadata": {
        "id": "ef737a52"
      },
      "source": [
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9654ee4",
      "metadata": {
        "id": "c9654ee4"
      },
      "source": [
        "## Logistic Regression "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fac89f8",
      "metadata": {
        "id": "5fac89f8"
      },
      "outputs": [],
      "source": [
        "from sklearn import pipeline, feature_selection, linear_model, preprocessing, metrics, model_selection\n",
        "\n",
        "first_pipe = pipeline.Pipeline([\n",
        "    (\"scale\", preprocessing.StandardScaler()),\n",
        "    (\"selection\", feature_selection.SelectPercentile(feature_selection.f_regression, percentile=50)),\n",
        "    (\"regression\", linear_model.LinearRegression()),\n",
        "])\n",
        "\n",
        "second_pipe = pipeline.Pipeline([\n",
        "    (\"scale\", preprocessing.StandardScaler()),\n",
        "    (\"selection\", feature_selection.SelectPercentile(feature_selection.f_regression, percentile=50)),\n",
        "    (\"regression\", linear_model.Lasso(alpha=40)),\n",
        "])\n",
        "\n",
        "first_pipe.get_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0949c8ef",
      "metadata": {
        "id": "0949c8ef"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a8a204d",
      "metadata": {
        "id": "0a8a204d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MHq1r_wBjs7k"
      },
      "id": "MHq1r_wBjs7k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the following metrics for each model using test dataset\n",
        "---\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1 score"
      ],
      "metadata": {
        "id": "2RBdWxGCIx2i"
      },
      "id": "2RBdWxGCIx2i"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "metrics = list()\n",
        "cm = dict()\n",
        "\n",
        "for lab in coeff_labels:\n",
        "\n",
        "    # Precision, recall, f-score from the multi-class support function\n",
        "    precision, recall, fscore, _ = score(y_test, y_pred[lab], average='weighted')\n",
        "    \n",
        "    # The usual way to calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred[lab])\n",
        "    \n",
        "    # ROC-AUC scores can be calculated by binarizing the data\n",
        "    auc = roc_auc_score(label_binarize(y_test, classes=[0,1,2,3,4,5]),\n",
        "              label_binarize(y_pred[lab], classes=[0,1,2,3,4,5]), \n",
        "              average='weighted')\n",
        "    \n",
        "    # Last, the confusion matrix\n",
        "    cm[lab] = confusion_matrix(y_test, y_pred[lab])\n",
        "    \n",
        "    metrics.append(pd.Series({'precision':precision, 'recall':recall, \n",
        "                              'fscore':fscore, 'accuracy':accuracy,\n",
        "                              'auc':auc}, \n",
        "                             name=lab))\n",
        "\n",
        "metrics = pd.concat(metrics, axis=1)"
      ],
      "metadata": {
        "id": "xePrYe79I1PU"
      },
      "id": "xePrYe79I1PU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating Confusion Matrix\n",
        "---\n",
        "Display or plot the confusion matrix for each model.\n"
      ],
      "metadata": {
        "id": "hFZ3qo3ej2aJ"
      },
      "id": "hFZ3qo3ej2aJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "mG644YYYj_mG"
      },
      "id": "mG644YYYj_mG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axList = plt.subplots(nrows=2, ncols=2)\n",
        "axList = axList.flatten()\n",
        "fig.set_size_inches(12, 10)\n",
        "\n",
        "axList[-1].axis('off')\n",
        "\n",
        "for ax,lab in zip(axList[:-1], coeff_labels):\n",
        "    sns.heatmap(cm[lab], ax=ax, annot=True, fmt='d');\n",
        "    ax.set(title=lab);\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "4ZNdtcx2kBqg"
      },
      "id": "4ZNdtcx2kBqg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning Curve\n",
        "---\n",
        "To know if we are overfit or underfit, we need to plot a learning curve. A learning curve plots performance (either error or score) against some measure of complexity."
      ],
      "metadata": {
        "id": "_jUgMhPGkS9v"
      },
      "id": "_jUgMhPGkS9v"
    },
    {
      "cell_type": "markdown",
      "id": "d563ff97",
      "metadata": {
        "id": "d563ff97"
      },
      "source": [
        "\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import pipeline, feature_selection, linear_model, preprocessing, metrics, model_selection\n",
        "\n",
        "first_pipe = pipeline.Pipeline([\n",
        "    (\"scale\", preprocessing.StandardScaler()),\n",
        "    (\"selection\", feature_selection.SelectPercentile(feature_selection.f_regression, percentile=50)),\n",
        "    (\"regression\", linear_model.LinearRegression()),\n",
        "])\n",
        "\n",
        "second_pipe = pipeline.Pipeline([\n",
        "    (\"scale\", preprocessing.StandardScaler()),\n",
        "    (\"selection\", feature_selection.SelectPercentile(feature_selection.f_regression, percentile=50)),\n",
        "    (\"regression\", linear_model.Lasso(alpha=40)),\n",
        "])\n",
        "\n",
        "first_pipe.get_params()"
      ],
      "metadata": {
        "id": "-2HU20gTlfzg"
      },
      "id": "-2HU20gTlfzg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_list = np.linspace(1, 100, 25, dtype='int')\n",
        "train_score = []\n",
        "test_score = []\n",
        "\n",
        "for i, p in enumerate(p_list):\n",
        "\n",
        "    first_pipe.set_params(selection__percentile=p)\n",
        "    #second_pipe.set_params(selection__percentile=p)\n",
        "\n",
        "    score = model_selection.cross_validate(\n",
        "        first_pipe,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        scoring=\"r2\",\n",
        "        cv=5,\n",
        "        return_train_score=True)\n",
        "\n",
        "    train_score.append(score['train_score'].mean())\n",
        "    test_score.append(score['test_score'].mean())\n",
        "print(max(test_score))"
      ],
      "metadata": {
        "id": "R3_1NDyIlrFa"
      },
      "id": "R3_1NDyIlrFa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "\n",
        "plt.plot(p_list, train_score, label='train')\n",
        "plt.plot(p_list, test_score, label='test')\n",
        "plt.ylabel(\"$r^2$\")\n",
        "plt.xlabel(\"percent of features\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "LCjEOBxCluxG"
      },
      "id": "LCjEOBxCluxG",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}