{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/absolutemocha/sdaai/blob/main/20065320_Lim_Zhao_Hong_C2349C_AY2022CWF_(ver_for_edit).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFBg0LWyg1xn"
      },
      "source": [
        "# Deep Learning Fundamentals - Coursework Final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhOUorRO4rA0"
      },
      "source": [
        "## Lim Zhao Hong, Student ID: 20065320"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL7ve8l_sJWY"
      },
      "source": [
        "### Cats and Dog dataset: https://www.kaggle.com/datasets/erkamk/cat-and-dog-images-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1JYpAFNsJWa"
      },
      "source": [
        "### Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "201zzEINg1xo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import library to access google drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "#Grant access to file in google drive\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "ei7Pvp8Z2hNv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaSA3vzF5oBv",
        "outputId": "bca6e4e3-a113-451f-da19-a7b26fe85100"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg_cqiJHRpkV",
        "outputId": "f9b77d3c-193c-44ea-b9c9-d079580951aa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SDAAI/FA1-1-C2349C-A Deep Learning Fundamentals/CWF/Dog Cat Panda .jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATADIR = r\"drive/My Drive/SDAAI/FA1-1-C2349C-A Deep Learning Fundamentals/CWF/Dog Cat Panda .jpeg\"   \n",
        "\n",
        "%cd /content/drive/My Drive/SDAAI/FA1-1-C2349C-A Deep Learning Fundamentals/CWF/Dog Cat Panda .jpeg\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVz7Txs5ydSa",
        "outputId": "e493f3da-2cdb-4b6f-973b-64ac07dc5119"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/SDAAI/FA1-1-C2349C-A Deep Learning Fundamentals/CWF/Dog Cat Panda .jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    labels = {}\n",
        "    labels_r = {}\n",
        "    data = []\n",
        "    idx = -1\n",
        "    for folder in tqdm(os.listdir('/content/drive/My Drive/SDAAI/FA1-1-C2349C-A Deep Learning Fundamentals/CWF/Dog Cat Panda .jpeg')):\n",
        "        idx += 1\n",
        "        labels[folder] = idx\n",
        "        labels_r[idx] = folder\n",
        "        for file in os.listdir(f'/content/drive/My Drive/SDAAI/FA1-1-C2349C-A Deep Learning Fundamentals/CWF/Dog Cat Panda .jpeg/{folder}'):\n",
        "            img = cv2.imread(f'/content/drive/My Drive/SDAAI/FA1-1-C2349C-A Deep Learning Fundamentals/CWF/Dog Cat Panda .jpeg/{folder}/{file}')\n",
        "            #img = cv2.resize(img,(112,112))\n",
        "            #img = img / 255.0\n",
        "    np.random.shuffle(data)\n",
        "    X = []\n",
        "    y = []\n",
        "    for d in data:\n",
        "        X.append(d[0])\n",
        "        y.append(d[1])\n",
        "    X_train,X_test,y_train,y_test = train_test_split(X,y ,\n",
        "                                   random_state=104, \n",
        "                                   test_size=0.25, \n",
        "                                   shuffle=True)\n",
        "  \n",
        "\n",
        "\n",
        "    return X_train,X_test,y_train,y_test,X,y,labels,labels_r,idx,data\n",
        " \n",
        "        "
      ],
      "metadata": {
        "id": "j28S9Uz89DUe"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test,X,y,labels,labels_r,idx,data = load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "OB-y9S8WBtBa",
        "outputId": "0b2c9be5-c654-4b64-9d51-ef217da1b7a1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:21<00:00,  4.29s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-17504cbea357>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_r\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-464eeab8a5b6>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                                    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m104\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                    \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                                    shuffle=True)\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m     n_train, n_test = _validate_shuffle_split(\n\u001b[0;32m-> 2421\u001b[0;31m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2422\u001b[0m     )\n\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2099\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m             \u001b[0;34m\"aforementioned parameters.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2102\u001b[0m         )\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "X4MM6xuUie2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORIES = [\"cats\", \"dogs\"]\n",
        "\n",
        "for category in CATEGORIES:\n",
        "    path = os.path.join(DATADIR,category)\n",
        "    i=0\n",
        "    for img in os.listdir(path):\n",
        "        img = cv2.imread(os.path.join(path,img))\n",
        "        plt.imshow(img)\n",
        "        plt.title(('cats' if category == \"cats\" else 'dogs'))\n",
        "        plt.show()\n",
        "        plt.axis(\"off\")\n",
        "        i+=1\n",
        "        if i == 5:\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "lrPMsdbs53Gj",
        "outputId": "17d427c9-0422-4c9e-f740-702dd70f416e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-332c73b371a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATADIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/SDAAI/FA1-1-C2349C-A Deep Learning Fundamentals/CWF/Dog Cat Panda .jpeg/cats'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#df =pd.read_csv(\"drive/My Drive/SDAAI/FA1-1-C2349C-A Deep Learning Fundamentals/CWF/Dog Cat Panda/cats\")\n",
        "#df.head()\n",
        "\n",
        "#!ls content/drive/My Drive/SDAAI/FA1-1-C2349C-A Deep Learning Fundamentals/CWF/Dog Cat Panda/cats\n",
        "\n",
        "#fileList = drive.ListFile({'q': \"'1t4eOMjth2NWzO_29wfkp83wixeGQYLsW' in parents and trashed=false\"}).GetList()\n",
        "#for file in fileList:\n",
        "#  print('Title: %s, ID: %s' % (file['title'], file['id']))\n",
        "   # Get the folder ID that you want\n",
        "#  if(file['title'] == \"picture\"):\n",
        "#      fileID = file['id']\n",
        "  \n",
        "# Initialize GoogleDriveFile instance with file id.\n",
        "#file2 = drive.CreateFile({'id': fileID})\n",
        "#file2.Trash()  # Move file to trash.\n",
        "#file2.UnTrash()  # Move file out of trash.\n",
        "#file2.Delete()  # Permanently delete the file.\n",
        "\n",
        "\n",
        "\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "   \n",
        "# For using listdir()\n",
        "import os\n",
        "   \n",
        "  \n",
        "# Below code does the authentication\n",
        "# part of the code\n",
        "gauth = GoogleAuth()\n",
        "  \n",
        "# Creates local webserver and auto\n",
        "# handles authentication.\n",
        "gauth.LocalWebserverAuth()       \n",
        "drive = GoogleDrive(gauth)\n",
        "   \n",
        "# replace the value of this variable\n",
        "# with the absolute path of the directory\n",
        "path = r\"drive/My Drive/SDAAI/FA1-1-C2349C-A Deep Learning Fundamentals/CWF/Dog Cat Panda/cats\"   \n",
        "   \n",
        "# iterating thought all the files/folder\n",
        "# of the desired directory\n",
        "for x in os.listdir(path):\n",
        "   \n",
        "    f = drive.CreateFile({'title': x})\n",
        "    f.SetContentFile(os.path.join(path, x))\n",
        "    f.Upload()\n",
        "  \n",
        "    # Due to a known bug in pydrive if we \n",
        "    # don't empty the variable used to\n",
        "    # upload the files to Google Drive the\n",
        "    # file stays open in memory and causes a\n",
        "    # memory leak, therefore preventing its \n",
        "    # deletion\n",
        "    f = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "Odtsj9z2VD2_",
        "outputId": "ccf3538d-9c54-441a-9f0b-b58f2e272c9e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidConfigError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/oauth2client/clientsecrets.py\u001b[0m in \u001b[0;36m_loadfile\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'client_secrets.json'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidClientSecretsError\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydrive/auth.py\u001b[0m in \u001b[0;36mLoadClientConfigFile\u001b[0;34m(self, client_config_file)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m       \u001b[0mclient_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclientsecrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mclientsecrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidClientSecretsError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/oauth2client/clientsecrets.py\u001b[0m in \u001b[0;36mloadfile\u001b[0;34m(filename, cache)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_loadfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/oauth2client/clientsecrets.py\u001b[0m in \u001b[0;36m_loadfile\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    124\u001b[0m         raise InvalidClientSecretsError('Error opening file', exc.filename,\n\u001b[0;32m--> 125\u001b[0;31m                                         exc.strerror, exc.errno)\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_validate_clientsecrets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidClientSecretsError\u001b[0m: ('Error opening file', 'client_secrets.json', 'No such file or directory', 2)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidConfigError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0dc854bbc745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Creates local webserver and auto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# handles authentication.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mgauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLocalWebserverAuth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mdrive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleDrive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_import_hooks/_pydrive.py\u001b[0m in \u001b[0;36mPatchedLocalWebServerAuth\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttplib2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0morig_local_webserver_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mpydrive_auth_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGoogleAuth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLocalWebserverAuth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPatchedLocalWebServerAuth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydrive/auth.py\u001b[0m in \u001b[0;36m_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadCredentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetFlow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m       \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoratee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydrive/auth.py\u001b[0m in \u001b[0;36mGetFlow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m     if not all(config in self.client_config \\\n\u001b[1;32m    442\u001b[0m                for config in self.CLIENT_CONFIGS_LIST):\n\u001b[0;32m--> 443\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadClientConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     constructor_kwargs = {\n\u001b[1;32m    445\u001b[0m         \u001b[0;34m'redirect_uri'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'redirect_uri'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydrive/auth.py\u001b[0m in \u001b[0;36mLoadClientConfig\u001b[0;34m(self, backend)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mInvalidConfigError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please specify client config backend'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadClientConfigFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'settings'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadClientConfigSettings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydrive/auth.py\u001b[0m in \u001b[0;36mLoadClientConfigFile\u001b[0;34m(self, client_config_file)\u001b[0m\n\u001b[1;32m    386\u001b[0m       \u001b[0mclient_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclientsecrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mclientsecrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidClientSecretsError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mInvalidConfigError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid client secrets file %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m     if not client_type in (clientsecrets.TYPE_WEB,\n\u001b[1;32m    390\u001b[0m                            clientsecrets.TYPE_INSTALLED):\n",
            "\u001b[0;31mInvalidConfigError\u001b[0m: Invalid client secrets file ('Error opening file', 'client_secrets.json', 'No such file or directory', 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "file_id = '1t4eOMjth2NWzO_29wfkp83wixeGQYLsW' #<-- You add in here the id from you google drive file, you can find it\n",
        "\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "def downloadFiles(service, listOfFiles):\n",
        "    # Download all jpegs\n",
        "    for fileID in listOfFiles:\n",
        "        request = service.files().get_media(fileId=fileID['id'])\n",
        "        fh = io.FileIO(fileID['name'], 'wb')\n",
        "        downloader = MediaIoBaseDownload(fh, request)\n",
        "\n",
        "        done = False\n",
        "        while done is False:\n",
        "            status, done = downloader.next_chunk()\n",
        "            print(\"Downloading...\" + str(fileID['name']))\n",
        "\n",
        "\n",
        "#download = drive.CreateFile({'id': file_id})\n",
        "\n",
        "\n",
        "# Download the file to a local disc\n",
        "#download.GetContentFile('file.csv')\n",
        "#df  = pd.read_csv(\"file.csv\")\n",
        "#df.head()"
      ],
      "metadata": {
        "id": "zySzA6Vt_aQZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1t4eOMjth2NWzO_29wfkp83wixeGQYLsW'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "ltkYR7BWH1b-",
        "outputId": "07e26d36-1147-4e46-f1cf-f2b2366b873d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotDownloadableError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotDownloadableError\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-fd2ed8556cc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mfile_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1t4eOMjth2NWzO_29wfkp83wixeGQYLsW'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdownloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloaded content \"{}\"'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mGetContentString\u001b[0;34m(self, mimetype, encoding, remove_bom)\u001b[0m\n\u001b[1;32m    191\u001b[0m                     \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_bom\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchContent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36m_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoratee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_decorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mFetchContent\u001b[0;34m(self, mimetype, remove_bom)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       raise FileNotDownloadableError(\n\u001b[0;32m--> 265\u001b[0;31m         'No downloadLink/exportLinks for mimetype found in metadata')\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmimetype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'text/plain'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotDownloadableError\u001b[0m: No downloadLink/exportLinks for mimetype found in metadata"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DudD0N4SsJWi"
      },
      "source": [
        "### Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hV3LgpS6sJWk"
      },
      "outputs": [],
      "source": [
        "DATADIR = r\"C:/Users/Admin/Desktop/Republic Poly/FA1-1-C2349C-A Deep Learning Fundamentals/CWF/Dog and Cat .png/\"\n",
        "CATEGORIES = [\"Cat\", \"Dog\"]\n",
        "\n",
        "for category in CATEGORIES:\n",
        "    path = os.path.join(DATADIR,category)\n",
        "    i=0\n",
        "    for img in os.listdir(path):\n",
        "        img = cv2.imread(os.path.join(path,img))\n",
        "        plt.imshow(img)\n",
        "        plt.title(('Cat' if category == \"Cat\" else 'Dog'))\n",
        "        plt.show()\n",
        "        plt.axis(\"off\")\n",
        "        i+=1\n",
        "        if i == 5:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-fjEhIBsJWo"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur7oHRP0sJWp"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 180 \n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:\n",
        "        path = os.path.join(DATADIR,category)\n",
        "        class_num = CATEGORIES.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
        "                new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE)) \n",
        "                training_data.append([new_array,class_num])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "create_training_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sN-mozFlsJWt"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "for features,label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "X = np.array(X).reshape(-1,IMG_SIZE,IMG_SIZE)\n",
        "print(X.shape)\n",
        "X = X/255.0  \n",
        "X = X.reshape(-1,180,180,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkd8n02AsJWv"
      },
      "outputs": [],
      "source": [
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "Y = to_categorical(y, num_classes = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF4PkCWfsJWw"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=42)\n",
        "print(\"x_train shape\",X_train.shape)\n",
        "print(\"x_test shape\",X_val.shape)\n",
        "print(\"y_train shape\",Y_train.shape)\n",
        "print(\"y_test shape\",Y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaqcHwj1sJWx"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "from keras.utils.np_utils import to_categorical \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "model = Sequential()\n",
        "#\n",
        "model.add(Conv2D(filters = 16, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (180,180,1)))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "#\n",
        "model.add(Conv2D(filters = 64, kernel_size = (2,2),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# \n",
        "model.add(Flatten())\n",
        "model.add(Dense(96, activation = \"relu\"))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(2, activation = \"softmax\"))\n",
        "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "epochs = 20\n",
        "batch_size = 40\n",
        "datagen = ImageDataGenerator(   \n",
        "        rotation_range=15,\n",
        "        zoom_range = 0.1,\n",
        "        width_shift_range=0.1,  \n",
        "        height_shift_range=0.1,  \n",
        "        horizontal_flip=True,  \n",
        "        vertical_flip=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u9uUFrksJW1"
      },
      "outputs": [],
      "source": [
        "datagen.fit(X_train)\n",
        "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
        "                              steps_per_epoch = X_train.shape[0] // batch_size)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bXJsXMZsJW3"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"loss\"],c = \"purple\")\n",
        "plt.plot(history.history[\"val_loss\"],c = \"orange\")\n",
        "plt.title(\"Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend([\"train\", \"test\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8UrQW9PsJW5"
      },
      "source": [
        "#### Loss between train and test result show close matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-anZIGNsJW5"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"accuracy\"],c = \"purple\")\n",
        "plt.plot(history.history[\"val_accuracy\"],c = \"orange\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend([\"train\", \"test\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmiU7dnFsJW8"
      },
      "source": [
        "#### Accuracy between train and test result show close matching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se4PNq5ksJW_"
      },
      "source": [
        "## Hyperparameters tuning:  <br>1) Change dropout <br>2) Change compile optimiser to adam <br>3) Change learning rate to 0.01 <br>4) Add one more filter layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLk_ceS2sJXA"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = Sequential()\n",
        "#\n",
        "model.add(Conv2D(filters = 16, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (180,180,1)))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.1)) ##Change dropout to 0.1\n",
        "\n",
        "#\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.1)) ##Change dropout to 0.1\n",
        "\n",
        "#\n",
        "model.add(Conv2D(filters = 64, kernel_size = (2,2),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.1)) ##Change dropout to 0.1\n",
        "\n",
        "#\n",
        "model.add(Conv2D(filters = 128, kernel_size = (2,2),padding = 'Same', ##Add one more filter layer\n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.1)) ##Change dropout to 0.1\n",
        "\n",
        "# \n",
        "model.add(Flatten())\n",
        "model.add(Dense(96, activation = \"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(2, activation = \"softmax\")) \n",
        "optimizer = Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999) ##Change learning rate to 0.01\n",
        "model.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"]) ## Compile using adam\n",
        "epochs = 30\n",
        "batch_size = 40\n",
        "datagen = ImageDataGenerator(   \n",
        "        rotation_range=15,\n",
        "        zoom_range = 0.1,\n",
        "        width_shift_range=0.1,  \n",
        "        height_shift_range=0.1,  \n",
        "        horizontal_flip=True,  \n",
        "        vertical_flip=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDuFc7ThsJXB"
      },
      "outputs": [],
      "source": [
        "datagen.fit(X_train)\n",
        "history1 = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
        "                              steps_per_epoch = X_train.shape[0] // batch_size)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i5ndSsKsJXC"
      },
      "outputs": [],
      "source": [
        "plt.plot(history1.history[\"loss\"],c = \"purple\")\n",
        "plt.plot(history1.history[\"val_loss\"],c = \"orange\")\n",
        "plt.title(\"Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend([\"train\", \"test\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1I7M38SsJXD"
      },
      "outputs": [],
      "source": [
        "plt.plot(history1.history[\"accuracy\"],c = \"purple\")\n",
        "plt.plot(history1.history[\"val_accuracy\"],c = \"orange\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend([\"train\", \"test\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77ZjjDs0sJXF"
      },
      "source": [
        "#### Accuracy improve over the initial model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5I21cb5sJXG"
      },
      "source": [
        "# Transfer Learning using VGG16 architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coiimeXKsJXG"
      },
      "outputs": [],
      "source": [
        "from keras.applications import vgg16\n",
        "\n",
        "# importing VGG16 from keras with pre-trained weights that is trained on imagenet\n",
        "# include_top > whether to include the 3 fully-connected layers at the top of the network.\n",
        "# weights > to use the weights from pre-training on Imagenet\n",
        "vggModel = vgg16.VGG16(include_top=True, weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbI2vFjCsJXG"
      },
      "outputs": [],
      "source": [
        "vggModel.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6US6EEpsJXH"
      },
      "outputs": [],
      "source": [
        "# Randomly select an image with label for predict by origin VGG16, to checkout the correctiveness \n",
        "import random\n",
        "imgSize = len(X)\n",
        "\n",
        "selected = random.randint(0, imgSize)\n",
        "\n",
        "img = X[selected]\n",
        "\n",
        "plt.imshow(img)\n",
        "\n",
        "plt.axis('off')\n",
        "\n",
        "plt.title('Label: {}'.format(CATEGORIES[y[selected]]))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBmW-htMsJXI"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTlKAcGWsJXJ"
      },
      "outputs": [],
      "source": [
        "#### Preparing the image for prediction into VGG16\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# Create an image memory object\n",
        "im = Image.fromarray(img, 'RGB')\n",
        "\n",
        "# 224x224 is the default image size required by VGG16\n",
        "im = im.resize((224, 224))\n",
        "x = np.array(im)\n",
        "\n",
        "# Add a fourth dimension (since Keras expects a list of images)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "#im = Image.fromarray((x * 255).astype(np.uint8))\n",
        "\n",
        "# Normalize the input image's pixel values to the range used when training the neural network\n",
        "# This step is required if you are using the base VGG16 model without further training\n",
        "x = vgg16.preprocess_input(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3tVqyZJsJXK"
      },
      "outputs": [],
      "source": [
        "# Run the image through the deep neural network to make a prediction\n",
        "predictions = vggModel.predict(x)\n",
        "\n",
        "# Look up the names of the predicted classes. Index zero is the results for the first image.\n",
        "predicted_classes = vgg16.decode_predictions(predictions)\n",
        "\n",
        "for imagenet_id, name, likelihood in predicted_classes[0]:\n",
        "    print(\"Prediction: {} - {:2f}%\".format(name, likelihood*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D55eHLSKsJXL"
      },
      "source": [
        "# Transfer Learning using VGG19 architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkANntvqsJXN"
      },
      "source": [
        "## The concept of the VGG19 model (also VGGNet-19) is the same as the VGG16 except that it supports 19 layers. The “16” and “19” stand for the number of weight layers in the model (convolutional layers). This means that VGG19 has three more convolutional layers than VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrYgMhAAsJXQ"
      },
      "outputs": [],
      "source": [
        "from keras.applications import vgg19\n",
        "\n",
        "# importing VGG16 from keras with pre-trained weights that is trained on imagenet\n",
        "# include_top > whether to include the 3 fully-connected layers at the top of the network.\n",
        "# weights > to use the weights from pre-training on Imagenet\n",
        "vggModel1 = vgg19.VGG19(include_top=True, weights='imagenet')\n",
        "#IMAGE_SIZE = [224, 224] #Default image size for VGG16\n",
        "#vggModel = vgg19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYRliySmsJXQ"
      },
      "outputs": [],
      "source": [
        "vggModel1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWvT5luesJXR"
      },
      "outputs": [],
      "source": [
        "# Randomly select an image with label for predict by VGG19, to checkout the correctiveness \n",
        "import random\n",
        "imgSize = len(X)\n",
        "\n",
        "selected = random.randint(0, imgSize)\n",
        "\n",
        "img = X[selected]\n",
        "\n",
        "plt.imshow(img)\n",
        "\n",
        "plt.axis('off')\n",
        "\n",
        "plt.title('Label: {}'.format(CATEGORIES[y[selected]]))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY_rvPzNsJXR"
      },
      "source": [
        "## Data augmentation using ImageDataGenerator (Geometric transformation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roRxZ2l6sJXS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras.utils.np_utils as ku\n",
        "\n",
        "# Initialize the ImageDataGenerator for geometric transformation\n",
        "datagen = ImageDataGenerator(rescale=1./255,\n",
        "                             rotation_range=45,\n",
        "                             width_shift_range=[-8, 8],\n",
        "                             height_shift_range=[-8, 8],\n",
        "                             shear_range=45,\n",
        "                             zoom_range=[0.75, 1.25],\n",
        "                             horizontal_flip=True,\n",
        "                             vertical_flip=True,\n",
        "                             validation_split=0.2)\n",
        "\n",
        "# Convert the labels to one-hot vector\n",
        "y_train_cat = ku.to_categorical(Y_train)\n",
        "\n",
        "for batch_x, batch_y in datagen.flow(X_train, y_train_cat, batch_size=16):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    for i in range(16):\n",
        "        x = batch_x[i]\n",
        "        y = batch_y[i]\n",
        "        index = np.argmax(y)\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(x)\n",
        "        plt.axis('off')\n",
        "        plt.title('Label: {}'.format(CATEGORIES[index]))\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIsKZwFlsJXT"
      },
      "source": [
        "## Data augmentation using ImageDataGenerator (Colour space transformation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNGL9ZGBsJXT"
      },
      "outputs": [],
      "source": [
        "# Initialize the ImageDataGenerator for colour space transformation\n",
        "datagen = ImageDataGenerator(rescale=1./255,\n",
        "                             channel_shift_range=0.25,\n",
        "                             brightness_range=[0.2, 1.2])\n",
        "\n",
        "for batch_x, batch_y in datagen.flow(X_train, y_train_cat, batch_size=16):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    for i in range(16):\n",
        "        x = batch_x[i]\n",
        "        y = batch_y[i]\n",
        "        index = np.argmax(y)\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(x)\n",
        "        plt.axis('off')\n",
        "        plt.title('Label: {}'.format(CATEGORIES[index]))\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA9YIh8MsJXU"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1cWXqB_sJXU"
      },
      "source": [
        "### Hyperparameter tuning with Adam optimiser, adjustment in learning rate/dropout and an additional layer provide a better validation accuracy. <br> In term of accuracy, the model can be improved further"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}