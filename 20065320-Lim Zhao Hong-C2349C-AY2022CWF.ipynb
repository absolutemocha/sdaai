{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM4cm7UyL2yuMYDbKmls+/F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/absolutemocha/sdaai/blob/main/20065320-Lim%20Zhao%20Hong-C2349C-AY2022CWF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Learning CWF\n",
        "## Lim Zhao Hong (20065320)"
      ],
      "metadata": {
        "id": "WhPu6RFEnqro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PYSs-CoWovyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset is a collection of MRI photos. The aim to apply image analysis and classify MRI images into four classes: Benign Tumor, Malignant Tumor, Pituitary Tumor and no Tumor."
      ],
      "metadata": {
        "id": "XS2ah_cCn3bY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "6IOQJTt7nlXQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jRm27_8phWSn"
      },
      "outputs": [],
      "source": [
        "import keras, os\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from keras.applications import vgg16\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes=[]\n",
        "filename='../input/brain-tumor-classification-mri'\n",
        "for sub_folder in os.listdir(os.path.join(filename,'Training')):\n",
        "    classes.append(sub_folder)\n",
        "print(classes)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "sOtEc08enJxm",
        "outputId": "5ece3292-35c8-4b86-a0ed-72c4c1e2257e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d4c99f90b10b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../input/brain-tumor-classification-mri'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msub_folder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/brain-tumor-classification-mri/Training'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import skimage.transform\n",
        "import cv2\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Dimension of training data. If you are not feeding 224,224,3 into the VGG16, you will need to ensure \n",
        "# include_top=False when you import the VGG16 model (step 7.2.4)\n",
        "IMAGE_DIMS = (64, 64, 3)\n",
        "resized_train_images = []\n",
        "resized_test_images = []\n",
        "\n",
        "# Resize every image in the train and test dataset to intended dimension based on requirements\n",
        "for image in train_images:\n",
        "    image = cv2.resize(image, (IMAGE_DIMS[0], IMAGE_DIMS[1]))\n",
        "    image = img_to_array(image)\n",
        "    resized_train_images.append(image)\n",
        "    \n",
        "for image in test_images:\n",
        "    image = cv2.resize(image, (IMAGE_DIMS[0], IMAGE_DIMS[1]))\n",
        "    image = img_to_array(image)\n",
        "    resized_test_images.append(image)"
      ],
      "metadata": {
        "id": "tBnUKbHluIDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "# Convert to array and normalize the RGB values\n",
        "resized_train_images = np.array(resized_train_images, dtype=\"float32\") / 255.0\n",
        "resized_test_images = np.array(resized_test_images, dtype=\"float32\") / 255.0\n",
        "\n",
        "# One-hot encoding on the labels\n",
        "train_labels_cat = to_categorical(train_labels)\n",
        "test_labels_cat = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "LzGfMoBauI0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the VGG16 model"
      ],
      "metadata": {
        "id": "cLcIkrmwuNed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Model\n",
        "from keras.applications import vgg16\n",
        "from keras.layers import Dropout, Flatten, Dense"
      ],
      "metadata": {
        "id": "-efl2LbluPi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Load the VGG16 model without the top classification layer"
      ],
      "metadata": {
        "id": "NTMZn7YLuS1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_DIMS = (64, 64, 3)\n",
        "\n",
        "base_model = vgg16.VGG16(weights='imagenet', \n",
        "                       include_top=False, \n",
        "                       input_shape=IMAGE_DIMS)\n",
        "\n",
        "print(base_model.summary())"
      ],
      "metadata": {
        "id": "BJypveBOuXlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(base_model.layers):\n",
        "    print('Layer {}: {} ({})'.format(i, layer.name, layer.trainable))"
      ],
      "metadata": {
        "id": "yNI9YeOxudr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Freeze\" base layers of VGG16"
      ],
      "metadata": {
        "id": "jLIOcKcHuiiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "     layer.trainable = False"
      ],
      "metadata": {
        "id": "ABAr70CNuli1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(base_model.layers):\n",
        "    print('Layer {}: {} ({})'.format(i, layer.name, layer.trainable))"
      ],
      "metadata": {
        "id": "V_GN533ZunUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build classification layers\n",
        "add our classication layers on top the base VGG16 base layers for our dataset"
      ],
      "metadata": {
        "id": "xviZxb2LupTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "\n",
        "#creating own layers in addition to VGG16 as the base layers\n",
        "model = models.Sequential(base_model.layers)"
      ],
      "metadata": {
        "id": "I86JKvAxuuyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afterr CNN layers, we need to flatten and create our fully connected layers and final output laters for classifications\n",
        "# determine with you own estimation on the layers and nodes for your network. It does not need to be perfect, an estimation will work for a start\n",
        "# you can modify the following to further tune your model\n",
        "\n",
        "model.add(Flatten())\n",
        "# you can uncomment the following dense layer to your preference of accuracy\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "AWXVf3wbuz7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(model.layers):\n",
        "    print('Layer {}: {} ({})'.format(i, layer.name, layer.trainable))"
      ],
      "metadata": {
        "id": "b9G6q51Fu3H1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "pJu59wYsu5dM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform training on our dataset"
      ],
      "metadata": {
        "id": "bBXZBmHRu7PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify accordingly if you want to fine-tune your model\n",
        "history = model.fit(resized_train_images, train_labels_cat, validation_split=0.2, epochs=20, batch_size=32, verbose=1, shuffle=True)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(resized_test_images, test_labels_cat, verbose=1)\n",
        "print('Test loss: {:.4f}'.format(test_loss))\n",
        "print('Test accuracy: {:.4f}'.format(test_acc))"
      ],
      "metadata": {
        "id": "XZw8JDP5u9XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the \"transferred\" and \"re-trained\" model"
      ],
      "metadata": {
        "id": "XXWeCrjyu_rO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss(history):\n",
        "    train_loss = history.history['loss']\n",
        "    test_loss = history.history['val_loss']\n",
        "    x = list(range(1, len(test_loss) + 1))\n",
        "    plt.plot(x, test_loss, color='red', label='Val loss')\n",
        "    plt.plot(x, train_loss, label='Train loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss vs. Epoch')\n",
        "    plt.legend()\n",
        "    \n",
        "plot_loss(history)"
      ],
      "metadata": {
        "id": "FgZX3gw4vCMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracy(history):\n",
        "    train_acc = history.history['accuracy']\n",
        "    test_acc = history.history['val_accuracy']\n",
        "    x = list(range(1, len(test_acc) + 1))\n",
        "    plt.plot(x, test_acc, color='red', label='Val accuracy')\n",
        "    plt.plot(x, train_acc, label='Train accuracy')  \n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlim([0, 20])\n",
        "    plt.ylim([0, 100])\n",
        "    plt.title('Accuracy vs. Epoch')  \n",
        "    plt.legend(loc='lower right')\n",
        "\n",
        "plot_accuracy(history)"
      ],
      "metadata": {
        "id": "X4qjJlJHvEN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform Prediction\n",
        "Predict an image by randomly choosing 1"
      ],
      "metadata": {
        "id": "Uhx5b2U0vIhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "imgSize = len(resized_test_images)\n",
        "selected = random.randint(0, imgSize)\n",
        "img = resized_test_images[selected]\n",
        "\n",
        "# To create a mapping of the label class to allow display of the description instead of a number\n",
        "categories = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "class_index = np.where(test_labels_cat[selected] == 1)[0][0]\n",
        "plt.title('Label: {}'.format(categories[class_index]))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VKPSwxmTvHJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the image through the deep neural network to make a prediction\n",
        "image = np.expand_dims(img, axis=0)\n",
        "prob = model.predict(image)    \n",
        "    \n",
        "print('Probability: {}\\n'.format(prob[0]))\n",
        "idx = np.argmax(prob)\n",
        "predictions = categories[idx]\n",
        "print('Predicted class: {} - {}'.format(idx, predictions))"
      ],
      "metadata": {
        "id": "AXYe9pyZwOu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict an image by loading an image from local directory"
      ],
      "metadata": {
        "id": "W8eHCW81wSoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WUniV_J2wR-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify and run this if you are running jupyter on your local computer\n",
        "#file_path = os.path.join('sample_dataset', 'monkey_1.png')\n",
        "\n",
        "## uncomment line 8 to line 11 and modify accordingly to your folder if you are running on Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "colab_path = 'drive/My Drive/Colab Notebooks/SDAAI-C2349/LU08/sample_dataset/' # complete path in Google Drive as follows for file access\n",
        "file_path = colab_path + \"monkey_1.png\""
      ],
      "metadata": {
        "id": "DplSckJGwVBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# Load the image that is in the same directory as the script\n",
        "img2 = cv2.imread(file_path)\n",
        "\n",
        "# Pre-process the image for classification\n",
        "image2 = cv2.resize(img2, (IMAGE_DIMS[0], IMAGE_DIMS[1]))\n",
        "image2 = image2.astype(\"float\") / 255.0\n",
        "image2 = img_to_array(image2)\n",
        "image2 = np.expand_dims(image2, axis=0)\n",
        "\n",
        "# Classify the input image\n",
        "print(\"[INFO] classifying image...\")\n",
        "proba = model.predict(image2)\n",
        "idx = np.argmax(proba)\n",
        "predictions = categories[idx]\n",
        "print('Predicted class: {} - {}'.format(idx, predictions))"
      ],
      "metadata": {
        "id": "9pHelkaDwXe8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}